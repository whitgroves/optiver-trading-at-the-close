{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another rewrite because I had to rebuild my local environment for cudf + tensorflow to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # https://stackoverflow.com/questions/40426502/is-there-a-way-to-suppress-the-messages-tensorflow-prints\n",
    "import gc\n",
    "import typing as t\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from itertools import combinations\n",
    "try: # got tired of changing code between local and kaggle setup\n",
    "    import cudf.pandas\n",
    "    cudf.pandas.install() # must be called before pandas import\n",
    "except ModuleNotFoundError:\n",
    "    print('cudf not installed. Continuing with CPU dataframes.')\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import tensorflow as tf # https://github.com/tensorflow/tensorflow/issues/62075\n",
    "keras = tf.keras # https://github.com/microsoft/pylance-release/issues/1066\n",
    "from keras import Sequential, layers, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU present.\n"
     ]
    }
   ],
   "source": [
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    print('GPU present.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN = '.data/train.csv'\n",
    "DATA_TEST_X = '.data/test.csv'\n",
    "DATA_TEST_Y = '.data/revealed_targets.csv'\n",
    "\n",
    "KAGGLE_DATA_TRAIN = '/kaggle/input/optiver-trading-at-the-close/train.csv'\n",
    "KAGGLE_DATA_TEST_X = '/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv'\n",
    "KAGGLE_DATA_TEST_Y = '/kaggle/input/optiver-trading-at-the-close/example_test_files/revealed_targets.csv'\n",
    "\n",
    "DROPS = ['index', 'time_id', 'currently_scored', 'time_id_x', 'time_id_y', 'revealed_date_id', 'revealed_time_id']\n",
    "SORTS = ['date_id', 'seconds_in_bucket', 'stock_id']\n",
    "INDEX = 'row_id'\n",
    "\n",
    "N_FEATURES = 11 + 0 # update if/as features are engineered \n",
    "# +0  features => TBD <--- training score\n",
    "# +2  features => TBD ('volume', 'mid_price')\n",
    "# +5  features => TBD ('volume', 'mid_price', 'liquidity_imbalance', 'matched_imbalance', 'size_imbalance')\n",
    "# +20 features => TBD (previous 5 + combinations)\n",
    "\n",
    "# https://www.kaggle.com/code/verracodeguacas/high-speed-predictions-no-gpu\n",
    "def add_features(data:pd.DataFrame) -> pd.DataFrame: # data arrives sorted and pruned\n",
    "    df = data.copy()\n",
    "    df['volume'] = df.ask_size + df.bid_size\n",
    "    df['mid_price'] = (df.ask_price + df.bid_price) / 2\n",
    "    df['liquidity_imbalance'] = (df.bid_size-df.ask_size) / (df.bid_size+df.ask_size)\n",
    "    df['matched_imbalance'] = (df.imbalance_size-df.matched_size) / (df.matched_size+df.imbalance_size)\n",
    "    df['size_imbalance'] = df.bid_size / df.ask_size\n",
    "    # size_cols = [x for x in data.columns if 'size' in x]\n",
    "    # price_cols = [x for x in list(set(data.columns)-set(size_cols)) if 'p' in x] # filter for '_price' and 'wap'\n",
    "    # for c in combinations(price_cols, 2):\n",
    "    #     df[f'{c[0]}_{c[1]}_imbalance'] = (df[c[0]]-df[c[1]]) / (df[c[0]]+df[c[1]])\n",
    "    # # print(len(df.columns))\n",
    "    return df\n",
    "\n",
    "def preprocess(data:pd.DataFrame) -> pd.DataFrame: # separate for submission compat\n",
    "    df = data.reset_index().set_index(INDEX)\n",
    "    df = df.drop([col for col in DROPS if col in df.columns], axis=1)\n",
    "    df = df.sort_values(by=SORTS).drop(SORTS, axis=1)\n",
    "    # df = add_features(df)\n",
    "    df = (df - df.min()) / (df.max() - df.min())\n",
    "    df = df.ffill().fillna(0)\n",
    "    return df\n",
    "\n",
    "def load_vars(testing:bool=False) -> tuple[pd.DataFrame, pd.Series]:\n",
    "\n",
    "    def read_data(train, test_x, test_y):\n",
    "        if testing:\n",
    "            data = pd.merge(*[pd.read_csv(path) for path in [test_x, test_y]], on=SORTS) # https://stackoverflow.com/a/32041277/3178898\n",
    "            ycol = 'revealed_target'\n",
    "        else:\n",
    "            data = pd.read_csv(train, index_col=INDEX)\n",
    "            ycol = 'target'\n",
    "        return data, ycol\n",
    "    \n",
    "    try: # tired of switching local/kaggle setup\n",
    "        data, ycol = read_data(DATA_TRAIN, DATA_TEST_X, DATA_TEST_Y)\n",
    "    except FileNotFoundError:\n",
    "        data, ycol = read_data(KAGGLE_DATA_TRAIN, KAGGLE_DATA_TEST_X, KAGGLE_DATA_TEST_Y)\n",
    "\n",
    "    data = data.dropna(subset=[ycol]) # some targets are null\n",
    "    X = preprocess(data.drop(ycol, axis=1))\n",
    "    y = data[ycol]\n",
    "    return X, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(t.Protocol): # interface for any sklearn-API model\n",
    "    def fit(self, X, y, sample_weight=None): ...\n",
    "    def predict(self, X): ...\n",
    "    def get_params(self, deep=True): ...\n",
    "\n",
    "class ModelProfile: # wrapper to ensure model info for Ensemble\n",
    "    def __init__(self, model:Model, score:float, predict_kw:dict={}) -> None:\n",
    "        self.model = model\n",
    "        self.score = score\n",
    "        self.predict_kw = predict_kw\n",
    "\n",
    "class Ensemble: # https://www.kaggle.com/code/iqmansingh/optiver-4-fold-time-series-split-ensemble\n",
    "    def __init__(self, models:list[ModelProfile]=None, limit:int=None) -> None:\n",
    "        self.models = models or list[ModelProfile]()\n",
    "        self.limit = limit # see add()\n",
    "\n",
    "    @property\n",
    "    def best_score(self) -> float:\n",
    "        return min(m.score for m in self.models) if len(self) > 0 else None\n",
    "    \n",
    "    @property\n",
    "    def mean_score(self) -> float:\n",
    "        return sum(m.score for m in self.models) / len(self) if len(self) > 0 else None\n",
    "\n",
    "    # adds a model to the collection. if limit is set, will reject new models below the mean (when full)\n",
    "    def add(self, model: ModelProfile) -> bool:\n",
    "        if self.limit and len(self) >= self.limit and model.score > self.mean_score:\n",
    "            return False\n",
    "        self.models.append(model)\n",
    "        return True\n",
    "    \n",
    "    # returns all models with scores better than the current mean. can set a recursion number to prune multiple times.\n",
    "    def prune(self, recurse:int=1): # -> Ensemble\n",
    "        new = Ensemble([m for m in self.models if m.score <= self.mean_score])\n",
    "        return new.prune(recurse-1) if recurse > 1 else new\n",
    "    \n",
    "    # wrapper for Model.predict(). calls each of the models and returns the average prediction\n",
    "    def predict(self, X:pd.DataFrame) -> pd.DataFrame:\n",
    "        y = pd.DataFrame(index=X.index)\n",
    "        y['pred'] = 0\n",
    "        for model in self.models:\n",
    "            m_pred = model.model.predict(X, **model.predict_kw)\n",
    "            y.pred += m_pred.reshape(-1) # tensorflow\n",
    "        y.pred = y.pred / len(self)\n",
    "        return y\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.models)\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'<Ensemble ({len(self)} model(s); mean_score={self.mean_score}; best_score={self.best_score}; target_size={self.limit})>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepts a list of Models and returns an ensemble of the best performers.\n",
    "# An existing Ensemble can also be passed in, which will be updated and returned instead.\n",
    "def train_ensemble(models:list[Model], folds:int=5, ensemble:Ensemble=Ensemble()) -> Ensemble:\n",
    "\n",
    "    print(f'Pre-training setup...', end='\\r')\n",
    "    cv = TimeSeriesSplit(folds)\n",
    "    X, y = load_vars()\n",
    "    X_test, y_test = load_vars(testing=True)\n",
    "    \n",
    "    for model in models:\n",
    "        \n",
    "        # customize fit() and predict() kwargs for each model type\n",
    "        fit_kw = dict()\n",
    "        predict_kw = dict()\n",
    "        early_stop = False\n",
    "        model_class = type(model).__name__\n",
    "        match model_class:\n",
    "            case 'Sequential':\n",
    "                model.compile(optimizer='adam', loss='mae')\n",
    "                keras_kw = dict(batch_size=256, verbose=0)\n",
    "                fit_kw.update(keras_kw) #dict(epochs=10//folds, **keras_kw))\n",
    "                predict_kw.update(keras_kw)\n",
    "            case 'LGBMRegressor':\n",
    "                fit_kw.update(dict(verbose=False))\n",
    "                early_stop = 'early_stopping_round' in model.get_params()\n",
    "            case 'XGBRegressor':\n",
    "                fit_kw.update(dict(verbose=0))\n",
    "                early_stop = 'early_stopping_rounds' in model.get_params()\n",
    "        \n",
    "        # k-fold cross-validation\n",
    "        model_fails = 0\n",
    "        for i, (train, valid) in enumerate(cv.split(X)):\n",
    "            try: # sometimes a training round can fail, but I don't want to give up on the whole ensemble\n",
    "                \n",
    "                print(f'Training {model_class}: Fold {i + 1}/{folds} - Running...', end='\\r')\n",
    "                X_valid, y_valid = X.iloc[valid, :], y[valid]\n",
    "\n",
    "                fold_kw = {} # some kwargs rely on data that changes per fold\n",
    "                if early_stop:\n",
    "                    fold_kw['eval_set'] = [(X_valid, y_valid)]\n",
    "                    if model_class == 'LGBMRegressor': fold_kw['eval_metric'] = 'l1'\n",
    "                if model_class == 'Sequential':\n",
    "                    fold_kw['validation_data'] = (X_valid, y_valid)\n",
    "                fit_kw.update(fold_kw)\n",
    "\n",
    "                try: # sometimes the keywords work, sometimes they don't\n",
    "                    model.fit(X.iloc[train, :], y[train], **fit_kw)\n",
    "                except:\n",
    "                    model.fit(X.iloc[train, :], y[train], **fold_kw) # regardless, always want the early stop\n",
    "\n",
    "                mae_train = mean_absolute_error(y_valid, model.predict(X_valid, **predict_kw))\n",
    "                mae_test = mean_absolute_error(y_test, model.predict(X_test, **predict_kw))\n",
    "                \n",
    "                del X_valid, y_valid\n",
    "                print(f'Training {model_class}: Fold {i + 1}/{folds} - Complete.  \\n\\tTrain MAE:  {mae_train}\\n\\tTest MAE:   {mae_test}')\n",
    "\n",
    "                ensemble.add(ModelProfile(model, mae_test, predict_kw))\n",
    "                print(f'{ensemble}')\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f'Training {model_class}: Fold {i + 1}/{folds} - Error: {e.args}')\n",
    "                model_fails += 1\n",
    "                if model_fails > 1: break # consecutive failures are likely a misconfig on the model\n",
    "            \n",
    "            finally: # otherwise it's likely an out of memory error and we can move on\n",
    "                gc.collect()\n",
    "    \n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training setup...\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Sequential: Fold 1/2 - Complete.  \n",
      "\tTrain MAE:  6.544870035261917\n",
      "\tTest MAE:   5.390486159321856\n",
      "<Ensemble (1 model(s); mean_score=5.390486159321856; best_score=5.390486159321856; target_size=None)>\n",
      "Training Sequential: Fold 2/2 - Complete.  \n",
      "\tTrain MAE:  6.204855920523244\n",
      "\tTest MAE:   5.39063359790567\n",
      "<Ensemble (2 model(s); mean_score=5.390559878613763; best_score=5.390486159321856; target_size=None)>\n",
      "Training Sequential: Fold 1/2 - Complete.  \n",
      "\tTrain MAE:  6.549382497583903\n",
      "\tTest MAE:   5.457737969527803\n",
      "<Ensemble (3 model(s); mean_score=5.412952575585109; best_score=5.390486159321856; target_size=None)>\n",
      "Training Sequential: Fold 2/2 - Complete.  \n",
      "\tTrain MAE:  6.203263369442382\n",
      "\tTest MAE:   5.495910518966307\n",
      "<Ensemble (4 model(s); mean_score=5.433692061430408; best_score=5.390486159321856; target_size=None)>\n",
      "Training Sequential: Fold 1/2 - Complete.  \n",
      "\tTrain MAE:  6.545958775086783\n",
      "\tTest MAE:   5.390578563622552\n",
      "<Ensemble (5 model(s); mean_score=5.425069361868837; best_score=5.390486159321856; target_size=None)>\n",
      "Training Sequential: Fold 2/2 - Complete.  \n",
      "\tTrain MAE:  6.205052756021645\n",
      "\tTest MAE:   5.390964087817628\n",
      "<Ensemble (6 model(s); mean_score=5.419385149526968; best_score=5.390486159321856; target_size=None)>\n",
      "Training LGBMRegressor: Fold 1/2 - Complete.  \n",
      "\tTrain MAE:  6.49558653864362\n",
      "\tTest MAE:   5.424118845379246\n",
      "<Ensemble (7 model(s); mean_score=5.420061391791579; best_score=5.390486159321856; target_size=None)>\n",
      "Training LGBMRegressor: Fold 2/2 - Complete.  \n",
      "\tTrain MAE:  6.158963930615857\n",
      "\tTest MAE:   5.452881058739886\n",
      "<Ensemble (8 model(s); mean_score=5.4241638501601175; best_score=5.390486159321856; target_size=None)>\n"
     ]
    }
   ],
   "source": [
    "NN_DROPOUT = 0.3\n",
    "RANDOM_STATE = 25 # funnier than 24\n",
    "keras.utils.set_random_seed(RANDOM_STATE)\n",
    "gb_params = dict(random_state=RANDOM_STATE, n_jobs=16, learning_rate=0.2, max_depth=3, colsample_bytree=0.85, subsample=0.8, reg_alpha=500) # lgb and xgb have some overlap\n",
    "\n",
    "# current test: 10 epochs per fold vs 10 epochs overall vs <fold> epochs (i.e., 1 epoch per fold)\n",
    "# note this is with NO additional features, whereas benchmark has +5 (and 10/f epochs)\n",
    "# result: \n",
    "models = [\n",
    "    Sequential([ # benchmark: 5.4043550502492765 (2/5); 10e best: 5.401457811465988; 10/f best: 5.395060764482284; 1/f best: 5.390486159321856\n",
    "        layers.Dense(N_FEATURES, kernel_regularizer=regularizers.l1(0.001), input_shape=[N_FEATURES]),\n",
    "        layers.Dropout(NN_DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(N_FEATURES, kernel_regularizer=regularizers.l1(0.001), activation='relu'),\n",
    "        layers.Dropout(NN_DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(1)\n",
    "    ]),\n",
    "    Sequential([ # benchmark: 5.43891581273165 (1/5); 10e best: 6.478754201861217; 10/f best: 5.803956092486219; 1/f best: 5.457737969527803\n",
    "        layers.Dense(N_FEATURES*2, kernel_regularizer=regularizers.l1(0.001), input_shape=[N_FEATURES]),\n",
    "        layers.Dropout(NN_DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(N_FEATURES, kernel_regularizer=regularizers.l1(0.001), activation='tanh'), # <<--tanh is not the move, change back to N_FEATURES//2, relu\n",
    "        layers.Dropout(NN_DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(1)\n",
    "    ]),\n",
    "    Sequential([ # benchmark: 5.4263829906077365 (1/5); 10e best: 5.390621362794841 ; 10/f best: 5.390174899445438; 1/f best: 5.390578563622552\n",
    "        layers.Dense(N_FEATURES*2, kernel_regularizer=regularizers.l1(0.001), input_shape=[N_FEATURES]),\n",
    "        layers.Dropout(NN_DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(N_FEATURES, kernel_regularizer=regularizers.l1(0.001), activation='relu'),\n",
    "        layers.Dropout(NN_DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(1)\n",
    "    ]),\n",
    "    # LGBMR benchmark: 5.421243718047972 (3/5); 10e best: 5.456184417608288; 10/f best: 5.425122550420957; 1/f best: 5.424118845379246\n",
    "    LGBMRegressor(**gb_params, early_stopping_round=5, metric='l1', num_leaves=8, min_child_samples=2000, min_split_gain=0.001, verbosity=-1),\n",
    "    # XGBRegressor(**gb_params, early_stopping_rounds=5, eval_metric='mae', tree_method='hist', gamma=0.2, verbose=0),\n",
    "]\n",
    "\n",
    "ensemble = train_ensemble(models, folds=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Ensemble (8 model(s); mean_score=5.4241638501601175; best_score=5.390486159321856; target_size=None)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Ensemble (5 model(s); mean_score=5.39735625080939; best_score=5.390486159321856; target_size=None)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned = ensemble.prune(1)\n",
    "pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Ensemble (4 model(s); mean_score=5.390665602166926; best_score=5.390486159321856; target_size=None)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twice_pruned = ensemble.prune(2)\n",
    "twice_pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model:Model|Ensemble) -> float:\n",
    "    X_test, y_test = load_vars(testing=True)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "e_score = test_model(ensemble)\n",
    "p_score = test_model(pruned)\n",
    "t_score = test_model(twice_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.402608749320398"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.391107050004356"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.390769963287764"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = twice_pruned if t_score == min(e_score, p_score, t_score) else pruned if p_score < e_score else ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Ensemble (4 model(s); mean_score=5.390665602166926; best_score=5.390486159321856; target_size=None)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission compat check\n",
    "import optiver2023\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()\n",
    "\n",
    "for (test, revealed_targets, _) in iter_test:\n",
    "    X_test = preprocess(test)\n",
    "    y_pred = model.predict(X_test)\n",
    "    submission = test[['row_id']].set_index('row_id') # needed to match rows\n",
    "    submission['target'] = y_pred\n",
    "    submission = submission.reset_index() # convert back for final CSV write\n",
    "    env.predict(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>478_0_0</td>\n",
       "      <td>0.268041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>478_0_1</td>\n",
       "      <td>0.266230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>478_0_2</td>\n",
       "      <td>0.295883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>478_0_3</td>\n",
       "      <td>0.267925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>478_0_4</td>\n",
       "      <td>0.268709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32995</th>\n",
       "      <td>480_540_195</td>\n",
       "      <td>-0.042382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32996</th>\n",
       "      <td>480_540_196</td>\n",
       "      <td>-0.042386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32997</th>\n",
       "      <td>480_540_197</td>\n",
       "      <td>-0.042177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32998</th>\n",
       "      <td>480_540_198</td>\n",
       "      <td>-0.041872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32999</th>\n",
       "      <td>480_540_199</td>\n",
       "      <td>-0.042365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id    target\n",
       "0          478_0_0  0.268041\n",
       "1          478_0_1  0.266230\n",
       "2          478_0_2  0.295883\n",
       "3          478_0_3  0.267925\n",
       "4          478_0_4  0.268709\n",
       "...            ...       ...\n",
       "32995  480_540_195 -0.042382\n",
       "32996  480_540_196 -0.042386\n",
       "32997  480_540_197 -0.042177\n",
       "32998  480_540_198 -0.041872\n",
       "32999  480_540_199 -0.042365\n",
       "\n",
       "[33000 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    res = pd.read_csv('/kaggle/working/submission.csv') # sanity check\n",
    "except FileNotFoundError:\n",
    "    res = pd.read_csv('./.data/submission.csv')\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
