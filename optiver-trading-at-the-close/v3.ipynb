{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4efea51d",
   "metadata": {},
   "source": [
    "v2 made progress with not crashing the kernel but it's not fully compatible with the submission guidelines yet.\n",
    "\n",
    "plus the MAE bottomed out at ~6.3, which isn't even enough to crack the first page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3fa3187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import typing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "188e9700",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cudf.pandas\n",
    "import pandas as pd\n",
    "# import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "057810a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_imputer(data:pd.DataFrame, target:str, drops:list=[]) -> pd.DataFrame:\n",
    "    X_train = data[data[target].notna()].drop(drops, axis=1)\n",
    "    y_train = data[target].loc[data.index.isin(X_train.index)]\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    X_test = data[data[target].isna()].drop(drops, axis=1).dropna()\n",
    "    y_test = model.predict(X_test)\n",
    "    return pd.DataFrame(y_test, columns=[target], index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ec89851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_unit(data:pd.DataFrame, imputes:list[str]=[], skips:list[str]=[], lags:int=0) -> pd.DataFrame:\n",
    "    temp = data.copy()\n",
    "    # impute\n",
    "    for col in imputes:\n",
    "        # imp = regression_imputer(temp, col, drops=imputes)\n",
    "        temp = temp[col].fillna(0) #imp)\n",
    "    temp = temp.interpolate()\n",
    "    # normalize\n",
    "    skipped = temp[skips]\n",
    "    temp = temp.drop(skips, axis=1)\n",
    "    temp = (temp - temp.min()) / (temp.max() - temp.min())\n",
    "    # lag features\n",
    "    lagged = []\n",
    "    for i in range(1, lags+1):\n",
    "        lag = temp.shift(i)\n",
    "        lag.columns = [f'{col}_lag_{i}0s' for col in lag.columns]\n",
    "        lagged.append(lag)\n",
    "    # recombine\n",
    "    temp = temp.join(lagged, how='inner').dropna(axis=0)\n",
    "    temp = skipped.join(temp, how='inner')\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2000524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data:pd.DataFrame, **kwargs) -> pd.DataFrame:\n",
    "    data = data.reset_index().set_index(['stock_id', 'date_id', 'seconds_in_bucket']).sort_index()\n",
    "    preprocessed = []\n",
    "    for stock_id in range(200):\n",
    "        print(f'Preprocessing...{stock_id/2:04.1f}%', end='\\r')\n",
    "        stock = pd.DataFrame(data.loc[stock_id])\n",
    "        stock = preprocess_unit(stock, **kwargs)\n",
    "        stock['stock_id'] = stock_id\n",
    "        preprocessed.append(stock)\n",
    "    data = pd.concat(preprocessed).reset_index()\n",
    "    print('Preprocessing...Complete')\n",
    "    del preprocessed\n",
    "    data = data.sort_values(by=['time_id'])\n",
    "    data = data.drop(['stock_id', 'date_id', 'seconds_in_bucket', 'time_id'], axis=1)\n",
    "    data = data.set_index('row_id')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e32ba6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./.data/train.csv', index_col='row_id')\n",
    "data = data.dropna(subset=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e083c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.target\n",
    "X = data.drop('target', axis=1)\n",
    "del data # memory is at a premium here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "436c4ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...Complete\n"
     ]
    }
   ],
   "source": [
    "X = preprocess(X, imputes=['far_price', 'near_price'], skips=['time_id', 'row_id', 'imbalance_buy_sell_flag'], lags=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c0a6b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(typing.Protocol):\n",
    "    def fit(self, X, y, sample_weight=None): ...\n",
    "    def predict(self, X): ...\n",
    "\n",
    "def train_model(model:Model, X:pd.DataFrame, y:pd.Series, folds:int=5) -> Model:\n",
    "    for i, (i_train, i_valid) in enumerate(TimeSeriesSplit(n_splits=folds).split(X)):\n",
    "        print(f'CV Fold {i + 1} of {folds} - Running...', end='\\r')\n",
    "        try:\n",
    "            X_train, X_valid = X.iloc[i_train, :], X.iloc[i_valid, :]\n",
    "            y_train, y_valid = y[i_train], y[i_valid]\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_valid)\n",
    "            mae = mean_absolute_error(y_valid, y_pred)\n",
    "            del X_train, X_valid, y_train, y_valid, y_pred # yep...\n",
    "        except Exception as e:\n",
    "            print(f'CV Fold {i + 1} of {folds} - Failed: {e}')\n",
    "            print(f'Returning undertrained model ({i} folds)')\n",
    "            break\n",
    "        finally:\n",
    "            gc.collect() # it's a LOT of data\n",
    "        print(f'CV Fold {i + 1} of {folds} - Complete. MAE: {mae}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8e929c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Fold 1 of 4 - Complete. MAE: 5.914791973668544\n",
      "CV Fold 2 of 4 - Complete. MAE: 5.158742088106489\n",
      "CV Fold 3 of 4 - Complete. MAE: 4.769280972739363\n",
      "CV Fold 4 of 4 - Complete. MAE: 4.330236484052406\n"
     ]
    }
   ],
   "source": [
    "model = train_model(XGBRegressor(seed=25), X, y, folds=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6de60620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optiver2023\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b43da3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/media/whitgroves/Data/Repos/kaggle/optiver-trading-at-the-close/v3.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/whitgroves/Data/Repos/kaggle/optiver-trading-at-the-close/v3.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m counter \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/whitgroves/Data/Repos/kaggle/optiver-trading-at-the-close/v3.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m (test, revealed_targets, sample_submission) \u001b[39min\u001b[39;00m iter_test:\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/whitgroves/Data/Repos/kaggle/optiver-trading-at-the-close/v3.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mif\u001b[39;00m counter \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/whitgroves/Data/Repos/kaggle/optiver-trading-at-the-close/v3.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         \u001b[39mprint\u001b[39m(test\u001b[39m.\u001b[39mhead(\u001b[39m3\u001b[39m))\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for (test, revealed_targets, sample_submission) in iter_test:\n",
    "    if counter == 0:\n",
    "        print(test.head(3))\n",
    "        print(revealed_targets.head(3))\n",
    "        print(sample_submission.head(3))\n",
    "    # X = preprocess(test, skips=['far_price', 'near_price', 'time_id', 'row_id', 'imbalance_buy_sell_flag'], lags=6)\n",
    "    # sample_submission['target'] = model.predict(X)\n",
    "    env.predict(sample_submission)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing progress but ultimately failed because I can't get submissions to work. I need to re-design my process around it for v4."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
