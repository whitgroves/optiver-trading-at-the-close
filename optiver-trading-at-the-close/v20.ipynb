{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Largely built on [@iqmansingh's](https://www.kaggle.com/iqmansingh) notebook, [4-Fold Time-Series Split Ensemble](https://www.kaggle.com/code/iqmansingh/optiver-4-fold-time-series-split-ensemble). The core idea is still to build a voting ensemble on time series splits, but with score tracking so it can reject models that degrade performance.\n",
    "\n",
    "I eventually learned that scikit-learn has a built-in [`VotingRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingRegressor.html) class, (*shout-out to [@chinzorigtganbat's](https://www.kaggle.com/chinzorigtganbat) [VotingRegressor + Boosters](https://www.kaggle.com/code/chinzorigtganbat/votingregressor-boosters)*), but it's different enough from what I'm going for here that I decided not to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU detected.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "# import typing\n",
    "import joblib\n",
    "import warnings\n",
    "import itertools\n",
    "warnings.simplefilter('ignore') # ignore FutureWarnings; must precede pandas import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import sklearn.svm as svm\n",
    "import sklearn.impute as imp\n",
    "import sklearn.metrics as met\n",
    "import sklearn.model_selection as sel\n",
    "import matplotlib.pyplot as plt\n",
    "import typing_extensions as ext # used over vanilla typing since it backports 3.11+ features\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # ignore bugged CUDA errors; must precede tf import\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.disable_interactive_logging() # ensemble will provide its own condensed version\n",
    "print(('GPU available.' if len(tf.config.list_physical_devices('GPU')) > 0 else 'No GPU detected.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DATA_TRAIN = '.data/train.csv'\n",
    "LOCAL_DATA_TEST_X = '.data/test.csv'\n",
    "LOCAL_DATA_TEST_Y = '.data/revealed_targets.csv'\n",
    "\n",
    "KAGGLE_DATA_TRAIN = '/kaggle/input/optiver-trading-at-the-close/train.csv'\n",
    "KAGGLE_DATA_TEST_X = '/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv'\n",
    "KAGGLE_DATA_TEST_Y = '/kaggle/input/optiver-trading-at-the-close/example_test_files/revealed_targets.csv'\n",
    "\n",
    "DROPS = ['index', 'time_id', 'currently_scored', 'time_id_x', 'time_id_y', 'revealed_date_id', 'revealed_time_id', 'row_id']\n",
    "SORTS = ['date_id', 'stock_id', 'seconds_in_bucket'] # order matters here\n",
    "SKIPS = ['imbalance_buy_sell_flag', 'target']\n",
    "\n",
    "def preprocess(data:pd.DataFrame) -> pd.DataFrame: # separate from load_data() for submission compat\n",
    "    data = data.set_index(SORTS).sort_index()      # pushing these into a multi-index makes life easier down the road\n",
    "    skip = data[[col for col in SKIPS if col in data.columns]]\n",
    "    data = data.drop([col for col in [*DROPS, *SKIPS] if col in data.columns], axis=1)\n",
    "    data = data.groupby(level='stock_id').ffill()  # impute with last observation; groupby() ensures ffill() is per-stock, per-day\n",
    "    data = (data - data.mean()) / data.std(ddof=0) # normalize (z-score)\n",
    "    data = data.fillna(0)                          # clean columns that didn't ffill or with a stdev of 0 (i.e., only 1 unique value)\n",
    "    data = pd.concat([skip, data], axis=1, join='inner') # re-join with skipped columns\n",
    "    temp = data.index.to_frame().seconds_in_bucket       # encode seconds as sin/cos waves\n",
    "    data['seconds_in_bucket_sin'] = np.sin((temp * 2 * np.pi / 540))\n",
    "    data['seconds_in_bucket_cos'] = np.cos((temp * 2 * np.pi / 540))\n",
    "    return data\n",
    "\n",
    "def load_vars(test:bool=False) -> tuple[pd.DataFrame, pd.Series]: # returns training (or test) data for either local or kaggle setup\n",
    "    def read_data(train, test_x, test_y): # wrap call to read_csv() since test X and y values are stored separately and must be merged\n",
    "        if test: return pd.merge(*[pd.read_csv(path) for path in [test_x, test_y]], on=SORTS).rename(columns={'revealed_target':'target'})\n",
    "        else: return pd.read_csv(train)\n",
    "    try: data = read_data(LOCAL_DATA_TRAIN, LOCAL_DATA_TEST_X, LOCAL_DATA_TEST_Y)\n",
    "    except FileNotFoundError: data = read_data(KAGGLE_DATA_TRAIN, KAGGLE_DATA_TEST_X, KAGGLE_DATA_TEST_Y)\n",
    "    data = data.dropna(subset=['target']) # some rows have null targets\n",
    "    data = preprocess(data)\n",
    "    return data.drop('target', axis=1), data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionError(Exception): pass # specific error type so we can fail gracefully later on during training\n",
    "\n",
    "class IModel(ext.Protocol): # interface for any sklearn-API model https://scikit-learn.org/stable/developers/develop.html\n",
    "    def fit(self, X, y, **kwargs) -> ext.Self: ...\n",
    "    def predict(self, X, **kwargs) -> np.ndarray: ...\n",
    "    def get_params(self, deep=True) -> dict[str, ext.Any]: ...\n",
    "\n",
    "class SelectiveEnsemble:\n",
    "    def __init__(self, limit:int=None) -> None:\n",
    "        self.limit = limit # once len(models) >= limit, only add new models with scores below the mean\n",
    "        self.models = dict[str, IModel]()\n",
    "        self.scores = dict[str, float]()\n",
    "        self.kwargs = dict[str, dict]()\n",
    "        self.test_x, self.test_y = load_vars(test=True)\n",
    "    \n",
    "    @property\n",
    "    def mean_score(self) -> float:\n",
    "        return sum(self.scores[m] for m in self.models) / len(self) if len(self) > 0 else None\n",
    "    \n",
    "    @property\n",
    "    def best_score(self) -> float:\n",
    "        return min(self.scores[m] for m in self.models) if len(self) > 0 else None\n",
    "    \n",
    "    @property\n",
    "    def best_model(self) -> IModel:\n",
    "        return [self.models[m] for m in self.models if self.scores[m] == self.best_score][0]\n",
    "    \n",
    "    def add(self, model:IModel, name:str, kwargs:dict) -> tuple[bool, float]: # raises PredictionError\n",
    "        if name in self.models: name = f'{name}(1)'\n",
    "        pred = model.predict(self.test_x, **kwargs)\n",
    "        if len(np.unique(pred)) == 1: raise PredictionError('Model is guessing a constant value.')\n",
    "        if np.isnan(pred).any(): raise PredictionError('Model is guessing NaN.')\n",
    "        score = met.mean_absolute_error(self.test_y, pred)\n",
    "        if self.limit and len(self) >= self.limit and self.mean_score < score: return False, score\n",
    "        self.models[name] = model\n",
    "        self.scores[name] = score\n",
    "        self.kwargs[name] = kwargs\n",
    "        return True, score\n",
    "\n",
    "    def prune(self, limit:int=None) -> ext.Self: # removes models with scores above the mean; recurses if limit is set\n",
    "        pruned = SelectiveEnsemble(limit=(limit or self.limit))\n",
    "        pruned.models = {m:self.models[m] for m in self.models if self.scores[m] <= self.mean_score}\n",
    "        pruned.scores = {m:self.scores[m] for m in pruned.models}\n",
    "        pruned.kwargs = {m:self.kwargs[m] for m in pruned.models}\n",
    "        if pruned.limit and len(pruned) > pruned.limit > 1: return pruned.prune()\n",
    "        return pruned\n",
    "    \n",
    "    def predict(self, X:pd.DataFrame, **kwargs) -> np.ndarray: # predict() wrapper for soft voting\n",
    "        y = np.zeros(len(X))\n",
    "        for m in self.models:\n",
    "            pred = self.models[m].predict(X, **self.kwargs[m])\n",
    "            y += pred.reshape(-1) # reshape needed for tensorflow output; doesn't impact other model types\n",
    "        y = y / len(self)\n",
    "        return y\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.models)\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'<Ensemble ({len(self)} model(s); mean: {self.mean_score:.6f}; best: {self.best_score:.6f}; limit: {self.limit})>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ensemble(models:list[IModel], folds:int=5, ignore_errors:bool=True) -> SelectiveEnsemble:\n",
    "    print(f'Pre-training setup...', end='\\r')\n",
    "    ensemble = SelectiveEnsemble()\n",
    "    cv = sel.TimeSeriesSplit(folds)\n",
    "    X, y = load_vars()\n",
    "    for j, model in enumerate(models): # customize fit() and predict() kwargs for each model's type and params\n",
    "        fit_kw = dict()\n",
    "        predict_kw = dict()\n",
    "        model_class = type(model).__name__ # used over isinstance() to use match/case\n",
    "        match model_class:\n",
    "            case 'Sequential':\n",
    "                model.compile(optimizer='adam', loss='mae')\n",
    "                keras_kw = dict(batch_size=256, verbose=0)\n",
    "                fit_kw.update(keras_kw) # in testing, multiple epochs per fold did not help\n",
    "                predict_kw.update(keras_kw)\n",
    "                early_stop = True\n",
    "            case 'LGBMRegressor':\n",
    "                fit_kw.update(dict(verbose=False)) # verbose=0 throws an error\n",
    "                early_stop = 'early_stopping_round' in model.get_params()\n",
    "            case 'XGBRegressor':\n",
    "                fit_kw.update(dict(verbose=0))\n",
    "                early_stop = 'early_stopping_rounds' in model.get_params()\n",
    "            # I tried CatBoostRegressor but it consistently underperformed and caused too many issues\n",
    "        fails = 0\n",
    "        for i, (i_train, i_valid) in enumerate(cv.split(X)):\n",
    "            name = f'{j}_{model_class}_{i}'\n",
    "            msg = f'Model {j+1}/{len(models)}: Fold {i+1}/{folds}: {name}'\n",
    "            try: # fail gracefully instead of giving up on the whole ensemble\n",
    "                print(f'{msg} - Training...', end='\\r')\n",
    "                X_valid, y_valid = X.iloc[i_valid, :], y.iloc[i_valid]\n",
    "                early_stop_kw = {}\n",
    "                if early_stop:\n",
    "                    if model_class == 'Sequential': early_stop_kw['validation_data'] = (X_valid, y_valid)\n",
    "                    else: # LGB + XGB\n",
    "                        early_stop_kw['eval_set'] = [(X_valid, y_valid)]\n",
    "                        if model_class == 'LGBMRegressor': early_stop_kw['eval_metric'] = 'l1'\n",
    "                fit_kw.update(early_stop_kw)\n",
    "                try: model.fit(X.iloc[i_train, :], y.iloc[i_train], **fit_kw) # some kw fail on kaggle\n",
    "                except: model.fit(X.iloc[i_train, :], y.iloc[i_train], **early_stop_kw) # regardless, always want the early stop\n",
    "                del X_valid, y_valid\n",
    "                print(f'{msg} - Submitting to ensemble...', end='\\r')\n",
    "                if model_class == 'Sequential':\n",
    "                    clone = tf.keras.models.clone_model(model)\n",
    "                    clone.set_weights(model.get_weights())\n",
    "                res, score = ensemble.add((clone if clone else model), name, predict_kw)\n",
    "                print(f'{msg} - {(\"Accepted\" if res else \"Rejected\")} with score: {score}\\n\\t{ensemble}')\n",
    "                fails = 0 # reset fail counter to pick up consecutive fails only\n",
    "            except PredictionError as e: # these tend not to improve, so skip remaining folds and move to next model\n",
    "                print(f'{msg} - Stopped: {e}')\n",
    "                break\n",
    "            except Exception as e: # these are mostly out of memory errors, which can generally be ignored\n",
    "                if not ignore_errors: raise e # ...generally\n",
    "                print(f'{msg} - Error: {type(e).__name__}: {e}')\n",
    "                fails += 1\n",
    "                if fails > 1: break # consecutive failures are usually a misconfig, skip these models as well\n",
    "            finally: gc.collect()\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1/5: Fold 1/5: 0_Sequential_0 - Accepted with score: 5.404728162187584\n",
      "\t<Ensemble (1 model(s); mean: 5.404728; best: 5.404728; limit: None)>\n",
      "Model 1/5: Fold 2/5: 0_Sequential_1 - Accepted with score: 5.427675563546597\n",
      "\t<Ensemble (2 model(s); mean: 5.416202; best: 5.404728; limit: None)>\n",
      "Model 1/5: Fold 3/5: 0_Sequential_2 - Accepted with score: 5.418815320696783\n",
      "\t<Ensemble (3 model(s); mean: 5.417073; best: 5.404728; limit: None)>\n",
      "Model 1/5: Fold 4/5: 0_Sequential_3 - Accepted with score: 5.411176721801113\n",
      "\t<Ensemble (4 model(s); mean: 5.415599; best: 5.404728; limit: None)>\n",
      "Model 1/5: Fold 5/5: 0_Sequential_4 - Accepted with score: 5.408261905557092\n",
      "\t<Ensemble (5 model(s); mean: 5.414132; best: 5.404728; limit: None)>\n",
      "Model 2/5: Fold 1/5: 1_Sequential_0 - Accepted with score: 5.4277293444404835\n",
      "\t<Ensemble (6 model(s); mean: 5.416398; best: 5.404728; limit: None)>\n",
      "Model 2/5: Fold 2/5: 1_Sequential_1 - Accepted with score: 5.4439261755370625\n",
      "\t<Ensemble (7 model(s); mean: 5.420330; best: 5.404728; limit: None)>\n",
      "Model 2/5: Fold 3/5: 1_Sequential_2 - Accepted with score: 5.443824148952498\n",
      "\t<Ensemble (8 model(s); mean: 5.423267; best: 5.404728; limit: None)>\n",
      "Model 2/5: Fold 4/5: 1_Sequential_3 - Accepted with score: 5.442990824209432\n",
      "\t<Ensemble (9 model(s); mean: 5.425459; best: 5.404728; limit: None)>\n",
      "Model 2/5: Fold 5/5: 1_Sequential_4 - Accepted with score: 5.445738713725362\n",
      "\t<Ensemble (10 model(s); mean: 5.427487; best: 5.404728; limit: None)>\n",
      "Model 3/5: Fold 1/5: 2_Sequential_0 - Accepted with score: 5.44347258988527\n",
      "\t<Ensemble (11 model(s); mean: 5.428940; best: 5.404728; limit: None)>\n",
      "Model 3/5: Fold 2/5: 2_Sequential_1 - Accepted with score: 5.484777030836803\n",
      "\t<Ensemble (12 model(s); mean: 5.433593; best: 5.404728; limit: None)>\n",
      "Model 3/5: Fold 3/5: 2_Sequential_2 - Accepted with score: 5.478954046902436\n",
      "\t<Ensemble (13 model(s); mean: 5.437082; best: 5.404728; limit: None)>\n",
      "Model 3/5: Fold 4/5: 2_Sequential_3 - Accepted with score: 5.4813118554623115\n",
      "\t<Ensemble (14 model(s); mean: 5.440242; best: 5.404728; limit: None)>\n",
      "Model 3/5: Fold 5/5: 2_Sequential_4 - Accepted with score: 5.476807164930606\n",
      "\t<Ensemble (15 model(s); mean: 5.442679; best: 5.404728; limit: None)>\n",
      "Model 4/5: Fold 1/5: 3_LGBMRegressor_0 - Accepted with score: 5.476807165087859\n",
      "\t<Ensemble (16 model(s); mean: 5.444812; best: 5.404728; limit: None)>\n",
      "Model 4/5: Fold 2/5: 3_LGBMRegressor_1 - Accepted with score: 5.476807165087859\n",
      "\t<Ensemble (17 model(s); mean: 5.446694; best: 5.404728; limit: None)>\n",
      "Model 4/5: Fold 3/5: 3_LGBMRegressor_2 - Accepted with score: 5.476807165087859\n",
      "\t<Ensemble (18 model(s); mean: 5.448367; best: 5.404728; limit: None)>\n",
      "Model 4/5: Fold 4/5: 3_LGBMRegressor_3 - Accepted with score: 5.476807165087859\n",
      "\t<Ensemble (19 model(s); mean: 5.449864; best: 5.404728; limit: None)>\n",
      "Model 4/5: Fold 5/5: 3_LGBMRegressor_4 - Accepted with score: 5.476807165087859\n",
      "\t<Ensemble (20 model(s); mean: 5.451211; best: 5.404728; limit: None)>\n",
      "Model 5/5: Fold 1/5: 4_XGBRegressor_0 - Accepted with score: 5.476807165087859\n",
      "\t<Ensemble (21 model(s); mean: 5.452430; best: 5.404728; limit: None)>\n",
      "Model 5/5: Fold 2/5: 4_XGBRegressor_1 - Accepted with score: 5.476807165087859\n",
      "\t<Ensemble (22 model(s); mean: 5.453538; best: 5.404728; limit: None)>\n",
      "Model 5/5: Fold 3/5: 4_XGBRegressor_2 - Accepted with score: 5.476807165087859\n",
      "\t<Ensemble (23 model(s); mean: 5.454550; best: 5.404728; limit: None)>\n",
      "Model 5/5: Fold 4/5: 4_XGBRegressor_3 - Accepted with score: 5.476807165087859\n",
      "\t<Ensemble (24 model(s); mean: 5.455477; best: 5.404728; limit: None)>\n",
      "Model 5/5: Fold 5/5: 4_XGBRegressor_4 - Accepted with score: 5.476807165087859\n",
      "\t<Ensemble (25 model(s); mean: 5.456330; best: 5.404728; limit: None)>\n"
     ]
    }
   ],
   "source": [
    "N_FEATURES = len(load_vars(test=True)[0].columns)\n",
    "ACTIVATION_1 = 'tanh' # inputs are standardized so keep negative range\n",
    "ACTIVATION_2 = 'relu' # performed better than tanh, sigmoid\n",
    "DROPOUT = 0.5         # performed better than 0.3, 0.4\n",
    "RANDOM_STATE = 25     # funnier than 24\n",
    "\n",
    "layers = tf.keras.layers\n",
    "Sequential = tf.keras.Sequential\n",
    "regularizer = tf.keras.regularizers.l1(0.001)\n",
    "tf.keras.utils.set_random_seed(RANDOM_STATE)\n",
    "gb_params = dict(random_state=RANDOM_STATE, n_jobs=16, learning_rate=0.2, max_depth=3, colsample_bytree=0.85, subsample=0.8, reg_alpha=500) # lgb and xgb have some overlap\n",
    "\n",
    "models = [\n",
    "    Sequential([\n",
    "        layers.Dense(N_FEATURES, kernel_regularizer=regularizer, activation=ACTIVATION_1, input_shape=[N_FEATURES]),\n",
    "        layers.Dropout(DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(N_FEATURES//8, kernel_regularizer=regularizer, activation=ACTIVATION_2),\n",
    "        layers.Dropout(DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(1)\n",
    "    ]),\n",
    "    Sequential([\n",
    "        layers.Dense(N_FEATURES, kernel_regularizer=regularizer, activation=ACTIVATION_1, input_shape=[N_FEATURES]),\n",
    "        layers.Dropout(DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(N_FEATURES//4, kernel_regularizer=regularizer, activation=ACTIVATION_2),\n",
    "        layers.Dropout(DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(1)\n",
    "    ]),\n",
    "    Sequential([\n",
    "        layers.Dense(N_FEATURES, kernel_regularizer=regularizer, activation=ACTIVATION_1, input_shape=[N_FEATURES]),\n",
    "        layers.Dropout(DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(N_FEATURES//2, kernel_regularizer=regularizer, activation=ACTIVATION_2),\n",
    "        layers.Dropout(DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(1)\n",
    "    ]),\n",
    "    lgb.LGBMRegressor(**gb_params, early_stopping_round=5, metric='l1', num_leaves=8, min_child_samples=2000, min_split_gain=0.001, verbosity=-1),\n",
    "    xgb.XGBRegressor(**gb_params, early_stopping_rounds=5, eval_metric='mae', tree_method='hist', gamma=0.2),\n",
    "]\n",
    "\n",
    "ensemble = build_ensemble(models, ignore_errors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble: 5.456330448782001, 25 models (<all>)\n",
      "Pruned  : 5.428939951867208, 11 models (0_Sequential_0, 0_Sequential_1, 0_Sequential_2, 0_Sequential_3, 0_Sequential_4, 1_Sequential_0, 1_Sequential_1, 1_Sequential_2, 1_Sequential_3, 1_Sequential_4, 2_Sequential_0)\n",
      "Top N   : 5.408055596515264,  3 models (0_Sequential_0, 0_Sequential_3, 0_Sequential_4)\n"
     ]
    }
   ],
   "source": [
    "pruned = ensemble.prune()\n",
    "top = ensemble.prune(len(models))\n",
    "print(f'Ensemble: {ensemble.mean_score}, {len(ensemble)} models (<all>)')\n",
    "print(f'Pruned  : {pruned.mean_score}, {len(pruned)} models ({\", \".join([m for m in pruned.models])})')\n",
    "print(f'Top N   : {top.mean_score},  {len(top)} models ({\", \".join([m for m in top.models])})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise Exception # stop for manual eval\n",
    "model = pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>478_0_0</td>\n",
       "      <td>-0.434262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>478_0_1</td>\n",
       "      <td>1.742555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>478_0_2</td>\n",
       "      <td>2.301860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>478_0_3</td>\n",
       "      <td>-0.795397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>478_0_4</td>\n",
       "      <td>-0.853766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32995</th>\n",
       "      <td>480_540_195</td>\n",
       "      <td>0.176449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32996</th>\n",
       "      <td>480_540_196</td>\n",
       "      <td>-0.597093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32997</th>\n",
       "      <td>480_540_197</td>\n",
       "      <td>0.395880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32998</th>\n",
       "      <td>480_540_198</td>\n",
       "      <td>-0.046731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32999</th>\n",
       "      <td>480_540_199</td>\n",
       "      <td>-0.091706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id    target\n",
       "0          478_0_0 -0.434262\n",
       "1          478_0_1  1.742555\n",
       "2          478_0_2  2.301860\n",
       "3          478_0_3 -0.795397\n",
       "4          478_0_4 -0.853766\n",
       "...            ...       ...\n",
       "32995  480_540_195  0.176449\n",
       "32996  480_540_196 -0.597093\n",
       "32997  480_540_197  0.395880\n",
       "32998  480_540_198 -0.046731\n",
       "32999  480_540_199 -0.091706\n",
       "\n",
       "[33000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optiver2023\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()\n",
    "\n",
    "for (test, _, _) in iter_test:\n",
    "    X_test = preprocess(test)\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    submission = test[['row_id']].set_index('row_id') # needed to match rows\n",
    "    submission['target'] = y_pred\n",
    "    submission = submission.reset_index() # convert back for final CSV write\n",
    "    env.predict(submission)\n",
    "\n",
    "try:\n",
    "    res = pd.read_csv('/kaggle/working/submission.csv') # sanity check\n",
    "except FileNotFoundError:\n",
    "    res = pd.read_csv('./.data/submission.csv')\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
