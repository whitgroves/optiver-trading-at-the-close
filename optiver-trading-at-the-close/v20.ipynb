{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Largely built on [@iqmansingh's](https://www.kaggle.com/iqmansingh) notebook, [4-Fold Time-Series Split Ensemble](https://www.kaggle.com/code/iqmansingh/optiver-4-fold-time-series-split-ensemble), although this borrows the `reduce_mem_usage` and `imbalance_features` snippets as well. The core idea is still to build a voting ensemble on time series splits, but with score tracking so it can reject models that degrade performance.\n",
    "\n",
    "I eventually learned that scikit-learn has a built-in [`VotingRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingRegressor.html) class, (*shout-out to [@chinzorigtganbat's](https://www.kaggle.com/chinzorigtganbat) [VotingRegressor + Boosters](https://www.kaggle.com/code/chinzorigtganbat/votingregressor-boosters)*), but it's different enough from what I'm going for here that I decided not to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU detected.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "# import typing\n",
    "import warnings\n",
    "import itertools\n",
    "warnings.simplefilter('ignore') # ignore FutureWarnings; must precede pandas import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import sklearn.metrics as met\n",
    "import sklearn.model_selection as sel\n",
    "import typing_extensions as ext # used over vanilla typing since it backports 3.11+ features\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # ignore bugged CUDA errors; must precede tf import\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.disable_interactive_logging() # ensemble will provide its own condensed version\n",
    "print(('GPU available.' if len(tf.config.list_physical_devices('GPU')) > 0 else 'No GPU detected.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit(parallel=True)\n",
    "def compute_triplet_imbalance(values:np.ndarray, combo_indices:list[tuple[int, int, int]]) -> np.ndarray:\n",
    "    num_rows = values.shape[0]\n",
    "    num_combinations = len(combo_indices)\n",
    "    imbalance_features = np.empty((num_rows, num_combinations))\n",
    "    for i in nb.prange(num_combinations): # enumerate() works but prange() lets us run in parallel\n",
    "        a, b, c = combo_indices[i]\n",
    "        for j in nb.prange(num_rows):\n",
    "            _a, _b, _c = values[j, a], values[j, b], values[j, c]\n",
    "            max_val = max(_a, _b, _c)\n",
    "            min_val = min(_a, _b, _c)\n",
    "            mid_val = sum([_a, _b, _c])-max_val-min_val\n",
    "            imbalance_features[j, i] = np.nan if mid_val == min_val else (max_val-mid_val)/(mid_val-min_val)\n",
    "    return imbalance_features   \n",
    "\n",
    "def calculate_triplet_imbalance_numba(cols:list[str], data:pd.DataFrame) -> pd.DataFrame:\n",
    "    values = data[cols].values\n",
    "    combo_indices = []\n",
    "    columns = []\n",
    "    for a, b, c in itertools.combinations(cols, 3):\n",
    "        combo_indices.append(tuple([cols.index(col) for col in [a, b, c]]))\n",
    "        columns.append(f'{a}_{b}_{c}_imbalance')\n",
    "    features_array = compute_triplet_imbalance(values, combo_indices)\n",
    "    return pd.DataFrame(features_array, columns=columns)\n",
    "\n",
    "def imbalance_features(data:pd.DataFrame) -> pd.DataFrame:\n",
    "    prices = [*[col for col in data.columns if 'price' in col], 'wap']\n",
    "    sizes = [col for col in data.columns if 'size' in col]\n",
    "    data['volume'] = data.eval('ask_size+bid_size')\n",
    "    data['mid_price'] = data.eval('(ask_price+bid_price)/2')\n",
    "    data['liquidity_imbalance'] = data.eval('(bid_size-ask_size)/volume')\n",
    "    data['matched_imbalance'] = data.eval('(imbalance_size-matched_size)/(imbalance_size+matched_size)')\n",
    "    data['size_imbalance'] = data.eval('bid_size/ask_size')\n",
    "    data['imbalance_momentum'] = data.groupby(level='stock_id').imbalance_size.diff(periods=1) / data.matched_size\n",
    "    data['price_spread'] = data.eval('ask_price-bid_price')\n",
    "    data['spread_intensity'] = data.groupby(level='stock_id').price_spread.diff()\n",
    "    data['price_pressure'] = data.eval('imbalance_size*price_spread')\n",
    "    data['market_urgency'] = data.eval('price_spread*liquidity_imbalance')\n",
    "    data['depth_pressure'] = data.eval('(ask_size-bid_size)*(far_price-near_price)')\n",
    "    for cols in itertools.combinations(prices, 2):\n",
    "        data[f'{cols[0]}_{cols[1]}_imbalance'] = data.eval(f'({cols[0]}-{cols[1]})/({cols[0]}+{cols[1]})')\n",
    "    for cols in [['ask_price', 'bid_price', 'wap', 'reference_price'], sizes]:\n",
    "        triplet_feature = calculate_triplet_imbalance_numba(cols, data)\n",
    "        data[triplet_feature.columns] = triplet_feature.values\n",
    "    for func in ['mean', 'std', 'skew', 'kurt']:\n",
    "        data[f'all_prices_{func}'] = data[prices].agg(func, axis=1)\n",
    "        data[f'all_sizes_{func}'] = data[sizes].agg(func, axis=1)\n",
    "    for win in [1, 2, 3, 5, 8, 13]:\n",
    "        for col in ['matched_size', 'imbalance_size', 'reference_price', 'imbalance_buy_sell_flag']:\n",
    "            data[f'{col}_shift_{win}'] = data.groupby(level='stock_id')[col].shift(win)\n",
    "            data[f'{col}_pct_{win}'] = data.groupby(level='stock_id')[col].pct_change(win)\n",
    "        for col in ['ask_price', 'bid_price', 'ask_size', 'bid_size', 'market_urgency', 'imbalance_momentum', 'size_imbalance']:\n",
    "            data[f'{col}_diff_{win}'] = data.groupby(level='stock_id')[col].diff(win)\n",
    "    return data.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "def stock_features(data:pd.DataFrame) -> pd.DataFrame: # other_features() with the time features removed\n",
    "    gdf = data.groupby(level='stock_id')\n",
    "    stock_features = dict[str, pd.DataFrame]()\n",
    "    for feat in ['size', 'price']:\n",
    "        bid, ask = f'bid_{feat}', f'ask_{feat}'\n",
    "        stock_features[f'median_{feat}'] = gdf[bid].median()-gdf[ask].median()\n",
    "        stock_features[f'std_{feat}'] = gdf[bid].std()-gdf[ask].std()\n",
    "        stock_features[f'range_{feat}'] = gdf[bid].max()-gdf[ask].min()\n",
    "    return pd.merge(data, pd.DataFrame(stock_features), on=['stock_id'], how='inner')\n",
    "\n",
    "def reduce_mem_usage(data:pd.DataFrame, verbose:bool=False) -> pd.DataFrame: # 3.10+\n",
    "    if verbose: mem_start = data.memory_usage().sum()\n",
    "    for col in data.columns:\n",
    "        match data[col].dtype:\n",
    "            case 'object' | 'bool': continue\n",
    "            case 'int32' | 'int64':\n",
    "                for int_size in [np.int8, np.int16, np.int32]:\n",
    "                    if data[col].min() > np.iinfo(int_size).min and data[col].max() < np.iinfo(int_size).max:\n",
    "                        data[col] = data[col].astype(int_size)\n",
    "            case 'float32' | 'float64':\n",
    "                for float_size in [np.float16, np.float32]:\n",
    "                    if data[col].min() > np.finfo(float_size).min and data[col].max() < np.finfo(float_size).max:\n",
    "                        data[col] = data[col].astype(float_size)\n",
    "            case _: raise Exception(data[col].dtype)\n",
    "    if verbose:\n",
    "        mem_end = data.memory_usage().sum()\n",
    "        print(f'DataFrame memory reduced from {mem_start} to {mem_end}.')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "483b0856",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DATA_TRAIN = '.data/train.csv'\n",
    "LOCAL_DATA_TEST_X = '.data/test.csv'\n",
    "LOCAL_DATA_TEST_Y = '.data/revealed_targets.csv'\n",
    "\n",
    "KAGGLE_DATA_TRAIN = '/kaggle/input/optiver-trading-at-the-close/train.csv'\n",
    "KAGGLE_DATA_TEST_X = '/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv'\n",
    "KAGGLE_DATA_TEST_Y = '/kaggle/input/optiver-trading-at-the-close/example_test_files/revealed_targets.csv'\n",
    "\n",
    "DROPS = ['index', 'time_id', 'currently_scored', 'time_id_x', 'time_id_y', 'revealed_date_id', 'revealed_time_id', 'row_id']\n",
    "SORTS = ['date_id', 'stock_id', 'seconds_in_bucket'] # order matters here\n",
    "SKIPS = ['imbalance_buy_sell_flag', 'target']\n",
    "\n",
    "def preprocess(data:pd.DataFrame) -> pd.DataFrame: # separate from load_data() for submission compat\n",
    "    data = data.set_index(SORTS).sort_index()      # pushing these into a multi-index makes life easier down the road\n",
    "    data = imbalance_features(data)                # must precede standardization; requires SKIPS in data\n",
    "    skip = data[[col for col in SKIPS if col in data.columns]]\n",
    "    data = data.drop([col for col in [*DROPS, *SKIPS] if col in data.columns], axis=1)\n",
    "    data = data.groupby(level='stock_id').ffill()  # impute with last observation; groupby() ensures ffill() is per-stock, per-day\n",
    "    data = (data - data.mean()) / data.std(ddof=0) # normalize/standardize (z-score)\n",
    "    data = data.fillna(0)                          # clean columns that didn't ffill or with a stdev of 0 (i.e., only 1 unique value)\n",
    "    data = pd.concat([skip, data], axis=1, join='inner') # re-join with skipped columns\n",
    "    temp = data.index.to_frame().seconds_in_bucket       # encode seconds as sin/cos waves\n",
    "    data['seconds_in_bucket_sin'] = np.sin((temp * 2 * np.pi / 540))\n",
    "    data['seconds_in_bucket_cos'] = np.cos((temp * 2 * np.pi / 540))\n",
    "    return stock_features(data) # works best when called at the end\n",
    "\n",
    "def load_vars(test:bool=False) -> tuple[pd.DataFrame, pd.Series]: # returns training (or test) data for either local or kaggle setup\n",
    "    def read_data(train, test_x, test_y): # wrap call to read_csv() since test X and y values are stored separately and must be merged\n",
    "        if test: return pd.merge(*[pd.read_csv(path) for path in [test_x, test_y]], on=SORTS).rename(columns={'revealed_target':'target'})\n",
    "        else: return pd.read_csv(train)\n",
    "    try: data = read_data(LOCAL_DATA_TRAIN, LOCAL_DATA_TEST_X, LOCAL_DATA_TEST_Y)\n",
    "    except FileNotFoundError: data = read_data(KAGGLE_DATA_TRAIN, KAGGLE_DATA_TEST_X, KAGGLE_DATA_TEST_Y)\n",
    "    data = data.dropna(subset=['target']) # some rows have null targets\n",
    "    data = reduce_mem_usage(data) # must precede preprocess or kaggle will run out of data\n",
    "    data = preprocess(data)\n",
    "    return data.drop('target', axis=1), data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionError(Exception): pass # specific error type so we can fail gracefully later on during training\n",
    "\n",
    "class IModel(ext.Protocol): # interface for any sklearn-API model https://scikit-learn.org/stable/developers/develop.html\n",
    "    def fit(self, X, y, **kwargs) -> ext.Self: ...\n",
    "    def predict(self, X, **kwargs) -> np.ndarray: ...\n",
    "    def get_params(self, deep=True) -> dict[str, ext.Any]: ...\n",
    "\n",
    "class SelectiveEnsemble:\n",
    "    def __init__(self, limit:int=None) -> None:\n",
    "        self.limit = limit # once len(models) >= limit, only add new models with scores below the mean\n",
    "        self.models = dict[str, IModel]()\n",
    "        self.scores = dict[str, float]()\n",
    "        self.kwargs = dict[str, dict]()\n",
    "        self.test_x, self.test_y = load_vars(test=True)\n",
    "    \n",
    "    @property\n",
    "    def mean_score(self) -> float:\n",
    "        return sum(self.scores[m] for m in self.models) / len(self) if len(self) > 0 else None\n",
    "    \n",
    "    @property\n",
    "    def best_score(self) -> float:\n",
    "        return min(self.scores[m] for m in self.models) if len(self) > 0 else None\n",
    "    \n",
    "    @property\n",
    "    def best_model(self) -> IModel:\n",
    "        return [self.models[m] for m in self.models if self.scores[m] == self.best_score][0]\n",
    "    \n",
    "    def add(self, model:IModel, name:str, kwargs:dict) -> tuple[bool, float]: # raises PredictionError\n",
    "        if name in self.models: name = f'{name}(1)'\n",
    "        pred = model.predict(self.test_x, **kwargs)\n",
    "        if len(np.unique(pred)) == 1: raise PredictionError('Model is guessing a constant value.')\n",
    "        if np.isnan(pred).any(): raise PredictionError('Model is guessing NaN.')\n",
    "        score = met.mean_absolute_error(self.test_y, pred)\n",
    "        if self.limit and len(self) >= self.limit and self.mean_score < score: return False, score\n",
    "        self.models[name] = model\n",
    "        self.scores[name] = score\n",
    "        self.kwargs[name] = kwargs\n",
    "        return True, score\n",
    "\n",
    "    def prune(self, limit:int=None) -> ext.Self: # removes models with scores above the mean; recurses if limit is set\n",
    "        pruned = SelectiveEnsemble(limit=(limit or self.limit))\n",
    "        pruned.models = {m:self.models[m] for m in self.models if self.scores[m] <= self.mean_score}\n",
    "        pruned.scores = {m:self.scores[m] for m in pruned.models}\n",
    "        pruned.kwargs = {m:self.kwargs[m] for m in pruned.models}\n",
    "        if pruned.limit and len(pruned) > pruned.limit > 1: return pruned.prune()\n",
    "        return pruned\n",
    "    \n",
    "    def predict(self, X:pd.DataFrame, **kwargs) -> np.ndarray: # predict() wrapper for soft voting, kwargs for compat\n",
    "        y = np.zeros(len(X))\n",
    "        for m in self.models:\n",
    "            pred = self.models[m].predict(X, **self.kwargs[m])\n",
    "            y += pred.reshape(-1) # reshape needed for tensorflow output; doesn't impact other model types\n",
    "        y = y / len(self)\n",
    "        return y\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.models)\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'<Ensemble ({len(self)} model(s); mean: {self.mean_score:.6f}; best: {self.best_score:.6f}; limit: {self.limit})>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ensemble(models:list[IModel], folds:int=5, limit:int=None, skip_prediction_errors:bool=True, ignore_errors:bool=True) -> SelectiveEnsemble:\n",
    "    print(f'Pre-training setup...', end='\\r')\n",
    "    ensemble = SelectiveEnsemble(limit=limit)\n",
    "    cv = sel.TimeSeriesSplit(folds)\n",
    "    X, y = load_vars()\n",
    "    for j, model in enumerate(models): # customize fit() and predict() kwargs for each model's type and params\n",
    "        fit_kw = dict()\n",
    "        predict_kw = dict()\n",
    "        model_class = type(model).__name__ # used over isinstance() to use match/case\n",
    "        match model_class:\n",
    "            case 'Sequential':\n",
    "                model.compile(optimizer='adam', loss='mae')\n",
    "                keras_kw = dict(batch_size=256, verbose=0)\n",
    "                fit_kw.update(keras_kw) # in testing, multiple epochs per fold did not help\n",
    "                predict_kw.update(keras_kw)\n",
    "                early_stop = True\n",
    "            case 'LGBMRegressor':\n",
    "                fit_kw.update(dict(verbose=False)) # verbose=0 throws an error\n",
    "                early_stop = 'early_stopping_round' in model.get_params()\n",
    "            case 'XGBRegressor':\n",
    "                fit_kw.update(dict(verbose=0))\n",
    "                early_stop = 'early_stopping_rounds' in model.get_params()\n",
    "            # I tried CatBoostRegressor but it consistently underperformed and caused too many issues\n",
    "        fails = 0\n",
    "        for i, (i_train, i_valid) in enumerate(cv.split(X)):\n",
    "            name = f'{j}_{model_class}_{i}'\n",
    "            msg = f'Model {j+1}/{len(models)}: Fold {i+1}/{folds}: {name}'\n",
    "            try: # fail gracefully instead of giving up on the whole ensemble\n",
    "                print(f'{msg} - Training...', end='\\r')\n",
    "                X_valid, y_valid = X.iloc[i_valid, :], y.iloc[i_valid]\n",
    "                early_stop_kw = {}\n",
    "                if early_stop:\n",
    "                    if model_class == 'Sequential': early_stop_kw['validation_data'] = (X_valid, y_valid)\n",
    "                    else: # LGB + XGB\n",
    "                        early_stop_kw['eval_set'] = [(X_valid, y_valid)]\n",
    "                        if model_class == 'LGBMRegressor': early_stop_kw['eval_metric'] = 'l1'\n",
    "                fit_kw.update(early_stop_kw)\n",
    "                try: model.fit(X.iloc[i_train, :], y.iloc[i_train], **fit_kw) # some kw fail on kaggle\n",
    "                except: model.fit(X.iloc[i_train, :], y.iloc[i_train], **early_stop_kw) # regardless, always want the early stop\n",
    "                del X_valid, y_valid\n",
    "                print(f'{msg} - Submitting to ensemble...', end='\\r')\n",
    "                if model_class == 'Sequential':\n",
    "                    clone = tf.keras.models.clone_model(model)\n",
    "                    clone.set_weights(model.get_weights())\n",
    "                else: clone = None\n",
    "                res, score = ensemble.add((clone or model), name, predict_kw)\n",
    "                print(f'{msg} - {(\"Accepted\" if res else \"Rejected\")} with score: {score}\\n\\t{ensemble}')\n",
    "                fails = 0 # reset fail counter to pick up consecutive fails only\n",
    "            except PredictionError as e: # these tend not to improve, so skip remaining folds and move to next model\n",
    "                print(f'{msg} - Stopped: {e}')\n",
    "                if skip_prediction_errors: break\n",
    "            except Exception as e: # these are mostly out of memory errors, which can generally be ignored\n",
    "                if not ignore_errors: raise e # ...generally\n",
    "                print(f'{msg} - Error: {type(e).__name__}: {e}')\n",
    "                fails += 1\n",
    "                if fails > 1: break # consecutive failures are usually a misconfig, skip these models as well\n",
    "            finally: gc.collect() # memory is at a premium\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1/6: Fold 1/2: 0_Sequential_0 - Accepted with score: 5.476868629455566\n",
      "\t<Ensemble (1 model(s); mean: 5.476869; best: 5.476869; limit: 12)>\n",
      "Model 1/6: Fold 2/2: 0_Sequential_1 - Accepted with score: 5.469015598297119\n",
      "\t<Ensemble (2 model(s); mean: 5.472942; best: 5.469016; limit: 12)>\n",
      "Model 2/6: Fold 1/2: 1_Sequential_0 - Accepted with score: 5.485466003417969\n",
      "\t<Ensemble (3 model(s); mean: 5.477117; best: 5.469016; limit: 12)>\n",
      "Model 2/6: Fold 2/2: 1_Sequential_1 - Accepted with score: 5.468294620513916\n",
      "\t<Ensemble (4 model(s); mean: 5.474911; best: 5.468295; limit: 12)>\n",
      "Model 3/6: Fold 1/2: 2_Sequential_0 - Accepted with score: 5.502244472503662\n",
      "\t<Ensemble (5 model(s); mean: 5.480378; best: 5.468295; limit: 12)>\n",
      "Model 3/6: Fold 2/2: 2_Sequential_1 - Accepted with score: 5.458706855773926\n",
      "\t<Ensemble (6 model(s); mean: 5.476766; best: 5.458707; limit: 12)>\n",
      "Model 4/6: Fold 1/2: 3_Sequential_0 - Accepted with score: 5.486048698425293\n",
      "\t<Ensemble (7 model(s); mean: 5.478092; best: 5.458707; limit: 12)>\n",
      "Model 4/6: Fold 2/2: 3_Sequential_1 - Accepted with score: 5.468384742736816\n",
      "\t<Ensemble (8 model(s); mean: 5.476879; best: 5.458707; limit: 12)>\n",
      "Model 5/6: Fold 1/2: 4_XGBRegressor_0 - Accepted with score: 8.947478294372559\n",
      "\t<Ensemble (9 model(s); mean: 5.862501; best: 5.458707; limit: 12)>\n",
      "Model 5/6: Fold 2/2: 4_XGBRegressor_1 - Accepted with score: 6.50213098526001\n",
      "\t<Ensemble (10 model(s); mean: 5.926464; best: 5.458707; limit: 12)>\n",
      "Model 6/6: Fold 1/2: 5_LGBMRegressor_0 - Accepted with score: 5.521983923248038\n",
      "\t<Ensemble (11 model(s); mean: 5.889693; best: 5.458707; limit: 12)>\n",
      "Model 6/6: Fold 2/2: 5_LGBMRegressor_1 - Accepted with score: 5.580793459048691\n",
      "\t<Ensemble (12 model(s); mean: 5.863951; best: 5.458707; limit: 12)>\n"
     ]
    }
   ],
   "source": [
    "N_FEATURES = len(load_vars(test=True)[0].columns) # \n",
    "ACTIVATION_1 = 'tanh' # inputs are standardized so keep negative range\n",
    "ACTIVATION_2 = 'relu' # performed better than tanh, sigmoid\n",
    "DROPOUT = 0.5         # performed better than 0.3, 0.4\n",
    "RANDOM_STATE = 25     # funnier than 24\n",
    "\n",
    "layers = tf.keras.layers\n",
    "Sequential = tf.keras.Sequential\n",
    "regularizer = tf.keras.regularizers.l1(0.001)\n",
    "tf.keras.utils.set_random_seed(RANDOM_STATE)\n",
    "gb_params = dict(random_state=RANDOM_STATE, n_jobs=16, learning_rate=0.2, max_depth=3, colsample_bytree=0.85, subsample=0.8, reg_alpha=500) # lgb/xgb overlap\n",
    "\n",
    "models = [ # order matters; frontloading stronger models will cause more rejections if limit is set\n",
    "    Sequential([\n",
    "        layers.Dense(N_FEATURES, kernel_regularizer=regularizer, activation=ACTIVATION_1, input_shape=[N_FEATURES]),\n",
    "        layers.Dropout(DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(N_FEATURES//8, kernel_regularizer=regularizer, activation=ACTIVATION_2),\n",
    "        layers.Dropout(DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(1)\n",
    "    ]),\n",
    "    Sequential([\n",
    "        layers.Dense(N_FEATURES, kernel_regularizer=regularizer, activation=ACTIVATION_1, input_shape=[N_FEATURES]),\n",
    "        layers.Dropout(DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(N_FEATURES//4, kernel_regularizer=regularizer, activation=ACTIVATION_2),\n",
    "        layers.Dropout(DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(1)\n",
    "    ]),\n",
    "    Sequential([\n",
    "        layers.Dense(N_FEATURES, kernel_regularizer=regularizer, activation=ACTIVATION_1, input_shape=[N_FEATURES]),\n",
    "        layers.Dropout(DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(N_FEATURES//2, kernel_regularizer=regularizer, activation=ACTIVATION_2),\n",
    "        layers.Dropout(DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(1)\n",
    "    ]),\n",
    "    Sequential([\n",
    "        layers.Dense(N_FEATURES, kernel_regularizer=regularizer, activation=ACTIVATION_1, input_shape=[N_FEATURES]),\n",
    "        layers.Dropout(DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(N_FEATURES, kernel_regularizer=regularizer, activation=ACTIVATION_2),\n",
    "        layers.Dropout(DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(1)\n",
    "    ]),\n",
    "    xgb.XGBRegressor(**gb_params, early_stopping_rounds=5, eval_metric='mae', tree_method='hist', gamma=0.2),\n",
    "    lgb.LGBMRegressor(**gb_params, early_stopping_round=5, metric='l1', num_leaves=8, min_child_samples=2000, min_split_gain=0.001, verbosity=-1),\n",
    "]\n",
    "\n",
    "ensemble = build_ensemble(models, limit=len(models)*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble: 5.863951, 12 models (<all>)\n",
      "Pruned  : 5.491781, 10 models (0_Sequential_0, 0_Sequential_1, 1_Sequential_0, 1_Sequential_1, 2_Sequential_0, 2_Sequential_1, 3_Sequential_0, 3_Sequential_1, 5_LGBMRegressor_0, 5_LGBMRegressor_1)\n",
      "Top N   : 5.466100,  4 models (0_Sequential_1, 1_Sequential_1, 2_Sequential_1, 3_Sequential_1)\n"
     ]
    }
   ],
   "source": [
    "pruned = ensemble.prune()\n",
    "top = ensemble.prune(len(models))\n",
    "print(f'Ensemble: {ensemble.mean_score:.6f}, {len(ensemble)} models (<all>)')\n",
    "print(f'Pruned  : {pruned.mean_score:.6f}, {len(pruned)} models ({\", \".join([m for m in pruned.models])})')\n",
    "print(f'Top N   : {top.mean_score:.6f},  {len(top)} models ({\", \".join([m for m in top.models])})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise Exception # stop for manual eval\n",
    "model = pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>478_0_0</td>\n",
       "      <td>-0.208320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>478_0_1</td>\n",
       "      <td>-0.233606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>478_0_2</td>\n",
       "      <td>0.059330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>478_0_3</td>\n",
       "      <td>-0.174838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>478_0_4</td>\n",
       "      <td>-0.232723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32995</th>\n",
       "      <td>480_540_195</td>\n",
       "      <td>-0.828346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32996</th>\n",
       "      <td>480_540_196</td>\n",
       "      <td>-0.927077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32997</th>\n",
       "      <td>480_540_197</td>\n",
       "      <td>-0.082095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32998</th>\n",
       "      <td>480_540_198</td>\n",
       "      <td>0.248340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32999</th>\n",
       "      <td>480_540_199</td>\n",
       "      <td>-1.233525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id    target\n",
       "0          478_0_0 -0.208320\n",
       "1          478_0_1 -0.233606\n",
       "2          478_0_2  0.059330\n",
       "3          478_0_3 -0.174838\n",
       "4          478_0_4 -0.232723\n",
       "...            ...       ...\n",
       "32995  480_540_195 -0.828346\n",
       "32996  480_540_196 -0.927077\n",
       "32997  480_540_197 -0.082095\n",
       "32998  480_540_198  0.248340\n",
       "32999  480_540_199 -1.233525\n",
       "\n",
       "[33000 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optiver2023\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()\n",
    "\n",
    "for (test, _, _) in iter_test:\n",
    "    X_test = preprocess(test)\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    submission = test[['row_id']].set_index('row_id') # needed to match rows\n",
    "    submission['target'] = y_pred\n",
    "    submission = submission.reset_index() # convert back for final CSV write\n",
    "    env.predict(submission)\n",
    "\n",
    "try:\n",
    "    res = pd.read_csv('/kaggle/working/submission.csv') # sanity check\n",
    "except FileNotFoundError:\n",
    "    res = pd.read_csv('./.data/submission.csv')\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
