{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "#   detect whether local or kaggle and skip training on the latter\n",
    "#   save/load models from file while training\n",
    "#   support generic model protocol\n",
    "#   use the engineered features everyone else is\n",
    "#   auto-select model by score\n",
    "#   (stretch) implement windowing with the engineered features\n",
    "#   (stretch) implement RNN https://www.tensorflow.org/tutorials/structured_data/time_series#recurrent_neural_network\n",
    "#   (stretch) voting ensemble\n",
    "#   (stretch) stacking ensemble https://scikit-learn.org/stable/modules/ensemble.html#stacked-generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import typing\n",
    "import joblib\n",
    "import warnings\n",
    "import itertools\n",
    "warnings.simplefilter('ignore') # should precede pandas import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import lightgbm as lgb\n",
    "import sklearn.svm as svm\n",
    "import sklearn.impute as imp\n",
    "import sklearn.metrics as met\n",
    "import sklearn.model_selection as sel\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # must precede tf import\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.disable_interactive_logging()\n",
    "tf.keras.utils.set_random_seed(25)\n",
    "if len(tf.config.list_physical_devices('GPU')) == 0: print('No GPU detected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df:pd.DataFrame, verbose:bool=False) -> pd.DataFrame:\n",
    "    if verbose: mem_start = df.memory_usage().sum()\n",
    "    for col in df.columns:\n",
    "        match df[col].dtype:\n",
    "            case 'object':\n",
    "                continue\n",
    "            case 'int32' | 'int64':\n",
    "                for int_size in [np.int8, np.int16, np.int32]:\n",
    "                    if df[col].min() > np.iinfo(int_size).min and df[col].max() < np.iinfo(int_size).max:\n",
    "                        df[col] = df[col].astype(int_size)\n",
    "            case 'float32' | 'float64':\n",
    "                for float_size in [np.float16, np.float32]:\n",
    "                    if df[col].min() > np.finfo(float_size).min and df[col].max() < np.finfo(float_size).max:\n",
    "                        df[col] = df[col].astype(float_size)\n",
    "            case _:\n",
    "                raise Exception(df[col].dtype)\n",
    "    if verbose:\n",
    "        mem_end = df.memory_usage().sum()\n",
    "        print(f'DataFrame memory reduced from {mem_start} to {mem_end}.')\n",
    "    return df\n",
    "\n",
    "try: # load data and identify local or kaggle setup\n",
    "    df = pd.read_csv('.data/train.csv')\n",
    "    LOCAL = True\n",
    "except FileNotFoundError:\n",
    "    df = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/train.csv')\n",
    "    LOCAL = False\n",
    "df = df.dropna(subset=['target'])\n",
    "df = df.reset_index(drop=True)\n",
    "df = reduce_mem_usage(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit(parallel=True)\n",
    "def compute_triplet_imbalance(df_values:np.ndarray, combo_indices:list[tuple[int, int, int]]) -> np.ndarray:\n",
    "    num_rows = df_values.shape[0]\n",
    "    num_combinations = len(combo_indices)\n",
    "    imbalance_features = np.empty((num_rows, num_combinations))\n",
    "    for i in nb.prange(num_combinations): # used instead of enumerate(combo_indices) to run in parallel\n",
    "        a, b, c = combo_indices[i]\n",
    "        for j in nb.prange(num_rows):\n",
    "            _a, _b, _c = df_values[j, a], df_values[j, b], df_values[j, c]\n",
    "            max_val = max(_a, _b, _c)\n",
    "            min_val = min(_a, _b, _c)\n",
    "            mid_val = sum([_a, _b, _c])-max_val-min_val\n",
    "            imbalance_features[j, i] = np.nan if mid_val == min_val else (max_val-mid_val)/(mid_val-min_val)\n",
    "    return imbalance_features   \n",
    "\n",
    "def calculate_triplet_imbalance_numba(cols:list[str], df:pd.DataFrame) -> pd.DataFrame:\n",
    "    df_values = df[cols].values\n",
    "    combo_indices = []\n",
    "    columns = []\n",
    "    for a, b, c in itertools.combinations(cols, 3):\n",
    "        combo_indices.append(tuple([cols.index(col) for col in [a, b, c]]))\n",
    "        columns.append(f'{a}_{b}_{c}_imbalance')\n",
    "    features_array = compute_triplet_imbalance(df_values, combo_indices)\n",
    "    features = pd.DataFrame(features_array, columns=columns)\n",
    "    return features\n",
    "\n",
    "def imbalance_features(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    prices = [*[col for col in df.columns if 'price' in col], 'wap']\n",
    "    sizes = [col for col in df.columns if 'size' in col]\n",
    "    df['volume'] = df.eval('ask_size+bid_size')\n",
    "    df['mid_price'] = df.eval('(ask_price+bid_price)/2')\n",
    "    df['liquidity_imbalance'] = df.eval('(bid_size-ask_size)/volume')\n",
    "    df['matched_imbalance'] = df.eval('(imbalance_size-matched_size)/(imbalance_size+matched_size)')\n",
    "    df['size_imbalance'] = df.eval('bid_size/ask_size')\n",
    "    df['imbalance_momentum'] = df.groupby('stock_id').imbalance_size.diff(periods=1) / df.matched_size\n",
    "    df['price_spread'] = df.eval('ask_price-bid_price')\n",
    "    df['spread_intensity'] = df.groupby('stock_id').price_spread.diff()\n",
    "    df['price_pressure'] = df.eval('imbalance_size*price_spread')\n",
    "    df['market_urgency'] = df.eval('price_spread*liquidity_imbalance')\n",
    "    df['depth_pressure'] = df.eval('(ask_size-bid_size)*(far_price-near_price)')\n",
    "    for cols in itertools.combinations(prices, 2):\n",
    "        df[f'{cols[0]}_{cols[1]}_imbalance'] = df.eval(f'({cols[0]}-{cols[1]})/({cols[0]}+{cols[1]})')\n",
    "    for cols in [['ask_price', 'bid_price', 'wap', 'reference_price'], sizes]:\n",
    "        triplet_feature = calculate_triplet_imbalance_numba(cols, df)\n",
    "        df[triplet_feature.columns] = triplet_feature.values\n",
    "    for func in ['mean', 'std', 'skew', 'kurt']:\n",
    "        df[f'all_prices_{func}'] = df[prices].agg(func, axis=1)\n",
    "        df[f'all_sizes_{func}'] = df[sizes].agg(func, axis=1)\n",
    "    for win in [1, 2, 3, 10]:\n",
    "        for col in ['matched_size', 'imbalance_size', 'reference_price', 'imbalance_buy_sell_flag']:\n",
    "            df[f'{col}_shift_{win}'] = df.groupby('stock_id')[col].shift(win)\n",
    "            df[f'{col}_pct_{win}'] = df.groupby('stock_id')[col].pct_change(win)\n",
    "        for col in ['ask_price', 'bid_price', 'ask_size', 'bid_size', 'market_urgency', 'imbalance_momentum', 'size_imbalance']:\n",
    "            df[f'{col}_diff_{win}'] = df.groupby('stock_id')[col].diff(win)\n",
    "    df = df.replace([np.inf, -np.inf], 0)\n",
    "    return df\n",
    "\n",
    "def other_features(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    df['weekday'] = df.eval('date_id%5')\n",
    "    df['seconds'] = df.eval('seconds_in_bucket%60')\n",
    "    df['minutes'] = df.eval('seconds_in_bucket//60')\n",
    "    # TODO: add sin/cos features (priority -1)\n",
    "    gdf = df.groupby('stock_id')\n",
    "    global_stock_id_feats = dict[str, pd.DataFrame]()\n",
    "    for feat in ['size', 'price']:\n",
    "        bid, ask = f'bid_{feat}', f'ask_{feat}'\n",
    "        global_stock_id_feats[f'median_{feat}'] = gdf[bid].median()-gdf[ask].median()\n",
    "        global_stock_id_feats[f'std_{feat}'] = gdf[bid].std()-gdf[ask].std()\n",
    "        global_stock_id_feats[f'ptp_{feat}'] = gdf[bid].max()-gdf[ask].min() # TODO: why 'ptp'?\n",
    "    for k, v in global_stock_id_feats.items():\n",
    "        df[f'global_{k}'] = df.stock_id.map(v.to_dict())\n",
    "    return df\n",
    "\n",
    "def generate_features(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    cols = [col for col in df.columns if col not in ['row_id', 'time_id', 'target']]\n",
    "    df = df[cols]\n",
    "    print('Building imbalance features...', end='\\r')\n",
    "    df = imbalance_features(df)\n",
    "    print('Building other features...    ', end='\\r')\n",
    "    df = other_features(df)\n",
    "    gc.collect()\n",
    "    features = [col for col in df.columns if col not in ['row_id', 'time_id', 'target', 'date_id']]\n",
    "    df = df[features]\n",
    "    print(f'Done. Total features in dataset: {len(df.columns)}')\n",
    "    return df\n",
    "\n",
    "generate_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Total features in dataset: 124\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    File \"/mnt/Data/Repos/kaggle/.cuda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/mnt/Data/Repos/kaggle/.cuda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/mnt/Data/Repos/kaggle/.cuda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/mnt/Data/Repos/kaggle/.cuda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/mnt/Data/Repos/kaggle/.cuda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/mnt/Data/Repos/kaggle/.cuda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 617, in call\n        raise NotImplementedError(\n\n    NotImplementedError: Exception encountered when calling layer 'model' (type Model).\n    \n    Unimplemented `tf.keras.Model.call()`: if you intend to create a `Model` with the Functional API, please provide `inputs` and `outputs` arguments. Otherwise, subclass `Model` with an overridden `call()` method.\n    \n    Call arguments received by layer 'model' (type Model):\n      • inputs=tf.Tensor(shape=(None, 124), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/mnt/Data/Repos/kaggle/optiver-trading-at-the-close/v19.ipynb Cell 10\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/Data/Repos/kaggle/optiver-trading-at-the-close/v19.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (_test, _, _) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(iter_test):\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/Data/Repos/kaggle/optiver-trading-at-the-close/v19.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     X_test \u001b[39m=\u001b[39m preprocess(_test)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/Data/Repos/kaggle/optiver-trading-at-the-close/v19.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_test, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/Data/Repos/kaggle/optiver-trading-at-the-close/v19.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     submission \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m], index\u001b[39m=\u001b[39mX_test\u001b[39m.\u001b[39mindex)\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/Data/Repos/kaggle/optiver-trading-at-the-close/v19.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     submission[\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m y_pred\n",
      "File \u001b[0;32m/mnt/Data/Repos/kaggle/.cuda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filet_xhltz6.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: in user code:\n\n    File \"/mnt/Data/Repos/kaggle/.cuda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/mnt/Data/Repos/kaggle/.cuda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/mnt/Data/Repos/kaggle/.cuda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/mnt/Data/Repos/kaggle/.cuda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/mnt/Data/Repos/kaggle/.cuda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/mnt/Data/Repos/kaggle/.cuda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 617, in call\n        raise NotImplementedError(\n\n    NotImplementedError: Exception encountered when calling layer 'model' (type Model).\n    \n    Unimplemented `tf.keras.Model.call()`: if you intend to create a `Model` with the Functional API, please provide `inputs` and `outputs` arguments. Otherwise, subclass `Model` with an overridden `call()` method.\n    \n    Call arguments received by layer 'model' (type Model):\n      • inputs=tf.Tensor(shape=(None, 124), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "import optiver2023 # submission compat check\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()\n",
    "\n",
    "for i, (_test, _, _) in enumerate(iter_test):\n",
    "    X_test = generate_features(_test)\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    submission = pd.DataFrame(columns=['target'], index=X_test.index)\n",
    "    submission['target'] = y_pred\n",
    "    # TODO: reformat for submission\n",
    "    assert all(x in submission.columns for x in ['row_id', 'target']) # sanity check 2\n",
    "    env.predict(submission)\n",
    "\n",
    "try:\n",
    "    res = pd.read_csv('/kaggle/working/submission.csv') # sanity check 1\n",
    "except FileNotFoundError:\n",
    "    res = pd.read_csv('./.data/submission.csv')\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ stopping here again. Going to start fresh from my best attempts (v13/14) then try to add these rewrites back in."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
