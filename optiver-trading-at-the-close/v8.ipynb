{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!UPDATE!!\n",
    "TRAINING_DATA = './.data/train.csv' \n",
    "# TESTING_DATA = './.data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3fa3187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import typing as t\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# %load_ext cudf.pandas\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit #, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5e98503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data:pd.DataFrame) -> pd.DataFrame:\n",
    "    data = data.reset_index().set_index('row_id')\n",
    "    for drop_col in ['index', 'time_id', 'currently_scored']:\n",
    "        if drop_col in data.columns:\n",
    "            data = data.drop(drop_col, axis=1)\n",
    "    id_cols = ['date_id', 'seconds_in_bucket', 'stock_id']\n",
    "    data = data.sort_values(by=id_cols)\n",
    "    data = data.drop(id_cols, axis=1)\n",
    "    data = (data - data.min()) / (data.max() - data.min())\n",
    "    data = data.ffill().fillna(0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e32ba6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_vars(path:str=TRAINING_DATA) -> tuple[pd.DataFrame, pd.Series]:\n",
    "    data = pd.read_csv(path, index_col='row_id')\n",
    "    data = data.dropna(subset=['target'])\n",
    "    y = data.target\n",
    "    X = data.drop('target', axis=1)\n",
    "    X = preprocess(X)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_training_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c0a6b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(t.Protocol):\n",
    "    def fit(self, X, y, sample_weight=None): ...\n",
    "    def predict(self, X): ...\n",
    "\n",
    "class Ensemble(list[Model]):\n",
    "    def __init__(self, models:list[Model]=None, limit:float=5.9873) -> None:\n",
    "        if models: \n",
    "            self.extend(models)\n",
    "        self.limit = limit\n",
    "    def predict(self, X:pd.DataFrame) -> pd.DataFrame:\n",
    "        y = pd.DataFrame(index=X.index)\n",
    "        y['pred'] = 0\n",
    "        for model in self:\n",
    "            y.pred += model.predict(X)\n",
    "        y.pred = y.pred / len(self)\n",
    "        return y\n",
    "\n",
    "def train_model(model:type|Model, model_kw:dict={}, folds:int=5, ens:Ensemble|None=None) -> Model|Ensemble:\n",
    "    gc.collect() # just in case \n",
    "    cv = TimeSeriesSplit(n_splits=folds)\n",
    "    folds = cv.get_n_splits()\n",
    "    if isinstance(model, type):\n",
    "        model = model(**model_kw)\n",
    "    model_class = type(model).__name__\n",
    "    early_stop = any(x in model_kw for x in ['early_stopping_rounds', 'early_stopping_round'])\n",
    "    for i, (i_train, i_valid) in enumerate(cv.split(X)): # X, y pulled from global scope\n",
    "        print(f'Training {model_class}: Fold {i + 1}/{folds} - Running...', end='\\r')\n",
    "        try:\n",
    "            early_stop_kw = {}\n",
    "            if early_stop:\n",
    "                early_stop_kw['eval_set'] = [(X.iloc[i_valid, :], y[i_valid])]\n",
    "                if model_class == 'LGBMRegressor': early_stop_kw['eval_metric'] = 'l1'\n",
    "            model.fit(X.iloc[i_train, :], y[i_train], verbose=False, **early_stop_kw)\n",
    "            mae = mean_absolute_error(y[i_valid], model.predict(X.iloc[i_valid, :]))\n",
    "            if ens is not None and mae < ens.limit:\n",
    "                ens.append(model)\n",
    "        except Exception as e:\n",
    "            print(f'Training {model_class}: Fold {i + 1}/{folds} - Failed: {e}')\n",
    "            print(f'Returning undertrained model ({i} folds)')\n",
    "            break\n",
    "        print(f'Training {model_class}: Fold {i + 1}/{folds} - Done. MAE: {mae}')\n",
    "    return ens if ens else model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def grid_search(model:Model, param_grid:dict, n_jobs:int=8) -> Model: # skip for now\n",
    "#     print('Starting grid search...', end='\\r')\n",
    "#     search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=n_jobs)\n",
    "#     search.fit(X, y) # X, y pulled from global scope\n",
    "#     print(f'Grid search complete. Best params: {search.best_params_}')\n",
    "#     return search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_params = dict(random_state=25, n_jobs=16,  learning_rate=0.2, max_depth=3, colsample_bytree=0.85, subsample=0.8, reg_alpha=500)\n",
    "xgb_params = dict(**shared_params, early_stopping_rounds=5, eval_metric='mae', tree_method='hist', gamma=0.2)\n",
    "lgb_params = dict(**shared_params, early_stopping_round=5, metric='l1', num_leaves=8, min_child_samples=2000, min_split_gain=0.001)\n",
    "cat_params = dict(random_state=25, learning_rate=0.2, max_depth=3, subsample=0.8) # like most cats, this one didn't want to listen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = cat.CatBoostRegressor(**cat_params)\n",
    "# model = grid_search(model, param_grid={'learning_rate':[0.05, 0.1, 0.2, 0.4, 0.8]}) # again, didn't listen... eta was >40m so I scrapped it\n",
    "# model = train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBRegressor: Fold 1/5 - Done. MAE: 7.3667617513962975\n",
      "Training XGBRegressor: Fold 2/5 - Done. MAE: 6.8421438828072665\n",
      "Training XGBRegressor: Fold 3/5 - Done. MAE: 6.1462978627363825\n",
      "Training XGBRegressor: Fold 4/5 - Done. MAE: 6.37172200017953\n",
      "Training XGBRegressor: Fold 5/5 - Done. MAE: 5.936866471891241\n",
      "Training LGBMRegressor: Fold 1/5 - Done. MAE: 7.341038789452177\n",
      "Training LGBMRegressor: Fold 2/5 - Done. MAE: 6.84366909148948\n",
      "Training LGBMRegressor: Fold 3/5 - Done. MAE: 6.146624723166877\n",
      "Training LGBMRegressor: Fold 4/5 - Done. MAE: 6.369221848953748\n",
      "Training LGBMRegressor: Fold 5/5 - Done. MAE: 5.9364673649185065\n",
      "Training CatBoostRegressor: Fold 1/5 - Done. MAE: 7.39178552248403\n",
      "Training CatBoostRegressor: Fold 2/5 - Done. MAE: 6.827364968846922\n",
      "Training CatBoostRegressor: Fold 3/5 - Done. MAE: 6.136876481842769\n",
      "Training CatBoostRegressor: Fold 4/5 - Done. MAE: 6.371412262442147\n",
      "Training CatBoostRegressor: Fold 5/5 - Done. MAE: 5.938775430049119\n"
     ]
    }
   ],
   "source": [
    "model = train_model(xgb.XGBRegressor,xgb_params, ens=Ensemble(limit=6.5))\n",
    "model = train_model(lgb.LGBMRegressor,lgb_params, ens=model)\n",
    "model = train_model(cat.CatBoostRegressor, cat_params, ens=model) # it's also incompatible with cudf...this will fail if using the cudf.pandas extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22e14226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission compat check\n",
    "import optiver2023\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()\n",
    "\n",
    "for (test, revealed_targets, _) in iter_test:\n",
    "    X_test = preprocess(test)\n",
    "    y_pred = model.predict(X_test)\n",
    "    submission = test[['row_id']].set_index('row_id') # needed to match rows\n",
    "    submission['target'] = y_pred\n",
    "    submission = submission.reset_index() # convert back for final CSV write\n",
    "    env.predict(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = pd.read_csv('/kaggle/working/submission.csv') # sanity check\n",
    "# res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This scored a 9.535 - a step in the wrong direction. Time to start looking at FE and NN.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
