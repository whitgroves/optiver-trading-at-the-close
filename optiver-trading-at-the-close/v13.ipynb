{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # https://stackoverflow.com/questions/40426502/is-there-a-way-to-suppress-the-messages-tensorflow-prints\n",
    "import gc\n",
    "import typing as t\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from itertools import combinations\n",
    "try: # got tired of changing code between local and kaggle setup\n",
    "    import cudf.pandas\n",
    "    cudf.pandas.install() # must be called before pandas import\n",
    "except ModuleNotFoundError:\n",
    "    print('cudf not installed. Continuing with CPU dataframes.')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import tensorflow as tf # https://github.com/tensorflow/tensorflow/issues/62075\n",
    "keras = tf.keras # https://github.com/microsoft/pylance-release/issues/1066\n",
    "from keras import Sequential, layers, regularizers\n",
    "from keras.models import clone_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(tf.config.list_physical_devices('GPU')) > 0: print('GPU available.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN = '.data/train.csv'\n",
    "DATA_TEST_X = '.data/test.csv'\n",
    "DATA_TEST_Y = '.data/revealed_targets.csv'\n",
    "\n",
    "KAGGLE_DATA_TRAIN = '/kaggle/input/optiver-trading-at-the-close/train.csv'\n",
    "KAGGLE_DATA_TEST_X = '/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv'\n",
    "KAGGLE_DATA_TEST_Y = '/kaggle/input/optiver-trading-at-the-close/example_test_files/revealed_targets.csv'\n",
    "\n",
    "DROPS = ['index', 'time_id', 'currently_scored', 'time_id_x', 'time_id_y', 'revealed_date_id', 'revealed_time_id']\n",
    "SORTS = ['date_id', 'seconds_in_bucket', 'stock_id']\n",
    "INDEX = 'row_id'\n",
    "\n",
    "N_FEATURES = 11 # update if/as features are engineered\n",
    "\n",
    "# https://www.kaggle.com/code/verracodeguacas/high-speed-predictions-no-gpu\n",
    "def add_features(data:pd.DataFrame) -> pd.DataFrame: # data arrives sorted and pruned\n",
    "    df = data.copy()\n",
    "    df['volume'] = df.ask_size + df.bid_size\n",
    "    df['mid_price'] = (df.ask_price + df.bid_price) / 2\n",
    "    df['liquidity_imbalance'] = (df.bid_size-df.ask_size) / (df.bid_size+df.ask_size)\n",
    "    df['matched_imbalance'] = (df.imbalance_size-df.matched_size) / (df.matched_size+df.imbalance_size)\n",
    "    df['size_imbalance'] = df.bid_size / df.ask_size\n",
    "    # size_cols = [x for x in data.columns if 'size' in x]\n",
    "    # price_cols = [x for x in list(set(data.columns)-set(size_cols)) if 'p' in x] # filter for '_price' and 'wap'\n",
    "    # for c in combinations(price_cols, 2):\n",
    "    #     df[f'{c[0]}_{c[1]}_imbalance'] = (df[c[0]]-df[c[1]]) / (df[c[0]]+df[c[1]])\n",
    "    # # print(len(df.columns))\n",
    "    return df\n",
    "\n",
    "def preprocess(data:pd.DataFrame) -> pd.DataFrame: # separate for submission compat\n",
    "    df = data.reset_index().set_index(INDEX)\n",
    "    df = df.drop([col for col in DROPS if col in df.columns], axis=1)\n",
    "    df = df.sort_values(by=SORTS).drop(SORTS, axis=1)\n",
    "    df = (df - df.mean()) / df.std() # (df - df.min()) / (df.max() - df.min()) # normalize\n",
    "    df = df.ffill().fillna(0) # \"impute\"\n",
    "    # df = add_features(df)\n",
    "    return df\n",
    "\n",
    "def load_vars(testing:bool=False) -> tuple[pd.DataFrame, pd.Series]:\n",
    "\n",
    "    def read_data(train, test_x, test_y):\n",
    "        if testing:\n",
    "            data = pd.merge(*[pd.read_csv(path) for path in [test_x, test_y]], on=SORTS) # https://stackoverflow.com/a/32041277/3178898\n",
    "            ycol = 'revealed_target'\n",
    "        else:\n",
    "            data = pd.read_csv(train, index_col=INDEX)\n",
    "            ycol = 'target'\n",
    "        return data, ycol\n",
    "    \n",
    "    try: # tired of switching local/kaggle setup\n",
    "        data, ycol = read_data(DATA_TRAIN, DATA_TEST_X, DATA_TEST_Y)\n",
    "    except FileNotFoundError:\n",
    "        data, ycol = read_data(KAGGLE_DATA_TRAIN, KAGGLE_DATA_TEST_X, KAGGLE_DATA_TEST_Y)\n",
    "\n",
    "    data = data.dropna(subset=[ycol]) # some targets are null\n",
    "    X = preprocess(data.drop(ycol, axis=1))\n",
    "    y = data[ycol]\n",
    "    return X, y \n",
    "\n",
    "# load_vars()[0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelProfile: # wrapper to ensure model info for Ensemble\n",
    "    def __init__(self, model:Sequential, score:float, predict_kw:dict={}) -> None:\n",
    "        self.model = model\n",
    "        self.score = score\n",
    "        self.predict_kw = predict_kw\n",
    "\n",
    "class Ensemble: # https://www.kaggle.com/code/iqmansingh/optiver-4-fold-time-series-split-ensemble\n",
    "    def __init__(self, models:list[ModelProfile]=None, target_size:int=None) -> None:\n",
    "        self.models = models or list[ModelProfile]()\n",
    "        self.target_size = target_size # see add()\n",
    "\n",
    "    @property\n",
    "    def mean_score(self) -> float:\n",
    "        return sum(m.score for m in self.models) / len(self) if len(self) > 0 else None\n",
    "    \n",
    "    @property\n",
    "    def best_score(self) -> float:\n",
    "        return min(m.score for m in self.models) if len(self) > 0 else None\n",
    "    \n",
    "    @property\n",
    "    def best_model(self) -> Sequential:\n",
    "        return [m.model for m in self.models if m.score == self.best_score][0]\n",
    "\n",
    "    # adds a model to the collection. if limit is set, will reject new models below the mean (when full)\n",
    "    def add(self, model: ModelProfile) -> bool:\n",
    "        if self.target_size and len(self) >= self.target_size and model.score > self.mean_score:\n",
    "            return False\n",
    "        self.models.append(model)\n",
    "        return True\n",
    "    \n",
    "    # removes all models above the current mean. if limit is passed or target size is set, repeats until that size (or 1) is reached\n",
    "    def prune(self, limit:int=None, inplace:bool=False): # -> Ensemble\n",
    "        pruned = Ensemble([m for m in self.models if m.score <= self.mean_score])\n",
    "        limit = limit or self.target_size\n",
    "        if limit is not None and len(pruned) > limit > 1:\n",
    "            return pruned.prune(limit=limit)\n",
    "        if inplace: self.models = pruned.models\n",
    "        return pruned\n",
    "    \n",
    "    # wrapper for Model.predict(). calls each of the models and returns the average prediction. kwargs is only for compat\n",
    "    def predict(self, X:pd.DataFrame, **kwargs) -> pd.DataFrame:\n",
    "        y = pd.DataFrame(index=X.index)\n",
    "        y['pred'] = 0\n",
    "        for m in self.models:\n",
    "            m_pred = m.model.predict(X, **m.predict_kw)\n",
    "            y.pred += m_pred.reshape(-1) # tensorflow\n",
    "        y.pred = y.pred / len(self)\n",
    "        return y\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.models)\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'<Ensemble ({len(self)} model(s); mean_score={self.mean_score:.6f}; best_score={self.best_score:.6f}; target_size={self.target_size})>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingError(Exception): pass\n",
    "\n",
    "def score_model(model:Sequential|Ensemble, predict_kw:dict={}, X_test:pd.DataFrame=None, y_test:pd.Series=None) -> float:\n",
    "    if any(x is None for x in [X_test, y_test]):\n",
    "        X_test, y_test = load_vars(testing=True)\n",
    "    y_pred = model.predict(X_test, **predict_kw)\n",
    "    if len(np.unique(y_pred)) == 1:\n",
    "        raise TrainingError('Model is guessing a constant value.')\n",
    "    # sometimes the model predicts NaN for some rows, which breaks mean_absolute_error << -- only when using additional features\n",
    "    if (isinstance(y_pred, pd.DataFrame) and y_pred.isna().sum().any() > 0) or (isinstance(y_pred, np.ndarray) and np.isnan(y_pred).any()):\n",
    "        raise TrainingError('Model is guessing NaN.')\n",
    "    return mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Accepts a list of models and returns an ensemble of the best performers.\n",
    "# An existing Ensemble can be passed in as well, which will will have its models updated inplace.\n",
    "def train_ensemble(models:list[Sequential], folds:int=5, ensemble:Ensemble=None, ignore_errors:bool=True) -> Ensemble:\n",
    "\n",
    "    print(f'Pre-training setup...', end='\\r')\n",
    "    ensemble = ensemble or Ensemble()\n",
    "    cv = TimeSeriesSplit(folds)\n",
    "    X, y = load_vars()\n",
    "    X_test, y_test = load_vars(testing=True)\n",
    "    \n",
    "    for j, model in enumerate(models):\n",
    "        model.compile(optimizer='adam', loss='mae')\n",
    "        for i, (train, valid) in enumerate(cv.split(X)):\n",
    "            msg = f'Training model: {(model.name or j)}: Fold {i + 1}/{folds}'\n",
    "            \n",
    "            try: # sometimes a training round can fail, but I don't want to give up on the whole ensemble   \n",
    "                print(f'{msg} - Running...', end='\\r')\n",
    "                X_valid, y_valid = X.iloc[valid, :], y[valid]\n",
    "\n",
    "                keras_kw = dict(batch_size=256, verbose=0)\n",
    "                model.fit(X.iloc[train, :], y[train], **keras_kw, validation_data=(X_valid, y_valid))\n",
    "                \n",
    "                mae_train = score_model(model, keras_kw, X_valid, y_valid)\n",
    "                mae_test = score_model(model, keras_kw, X_test, y_test)\n",
    "                \n",
    "                del X_valid, y_valid\n",
    "                print(f'{msg} - Complete.  \\n\\tTrain MAE:  {mae_train}\\n\\tTest MAE:   {mae_test}')\n",
    "\n",
    "                clone = clone_model(model) # https://stackoverflow.com/a/48552179/3178898\n",
    "                clone.set_weights(model.get_weights())\n",
    "                clone._name = f'{model.name}_{i}' # https://stackoverflow.com/a/63853924/3178898\n",
    "                \n",
    "                if ensemble.add(ModelProfile(clone, mae_test, keras_kw)):\n",
    "                    print(f'Model accepted: {ensemble}')\n",
    "                else:\n",
    "                    print(f'Model rejected: {ensemble}')\n",
    "            \n",
    "            except TrainingError as e: # these don't get better, stop trying to train this model\n",
    "                print(f'{msg} - Stopped: {e}') \n",
    "                break \n",
    "\n",
    "            except Exception as e: # these are usually out of memory errors, but generally want to skip these \n",
    "                if not ignore_errors: raise e # ...generally\n",
    "                print(f'{msg} - Error: {type(e).__name__}: {e}')\n",
    "            \n",
    "            finally: gc.collect() # memory is still at a premium\n",
    "    \n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_DROPOUT = 0.5\n",
    "NN_ACTIVATION_1 = 'tanh'\n",
    "NN_ACTIVATION_2 = 'relu'\n",
    "keras.utils.set_random_seed(25)\n",
    "\n",
    "models = [\n",
    "    Sequential([\n",
    "        layers.Dense(N_FEATURES, kernel_regularizer=regularizers.l1(0.001), activation=NN_ACTIVATION_1, input_shape=[N_FEATURES]),\n",
    "        layers.Dropout(NN_DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(N_FEATURES//8, kernel_regularizer=regularizers.l1(0.001), activation=NN_ACTIVATION_2),\n",
    "        layers.Dropout(NN_DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(1)\n",
    "    ], name='octo'),\n",
    "    Sequential([\n",
    "        layers.Dense(N_FEATURES, kernel_regularizer=regularizers.l1(0.001), activation=NN_ACTIVATION_1, input_shape=[N_FEATURES]),\n",
    "        layers.Dropout(NN_DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(N_FEATURES//4, kernel_regularizer=regularizers.l1(0.001), activation=NN_ACTIVATION_2),\n",
    "        layers.Dropout(NN_DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(1)\n",
    "    ], name='quad'),\n",
    "    Sequential([\n",
    "        layers.Dense(N_FEATURES, kernel_regularizer=regularizers.l1(0.001), activation=NN_ACTIVATION_1, input_shape=[N_FEATURES]),\n",
    "        layers.Dropout(NN_DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(N_FEATURES//2, kernel_regularizer=regularizers.l1(0.001), activation=NN_ACTIVATION_2),\n",
    "        layers.Dropout(NN_DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(1)\n",
    "    ], name='duce'),\n",
    "    Sequential([\n",
    "        layers.Dense(N_FEATURES, kernel_regularizer=regularizers.l1(0.001), activation=NN_ACTIVATION_1, input_shape=[N_FEATURES]),\n",
    "        layers.Dropout(NN_DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(N_FEATURES, kernel_regularizer=regularizers.l1(0.001), activation=NN_ACTIVATION_2),\n",
    "        layers.Dropout(NN_DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(1)\n",
    "    ], name='mono'),\n",
    "    Sequential([ \n",
    "        layers.Dense(N_FEATURES, kernel_regularizer=regularizers.l1(0.001), activation=NN_ACTIVATION_1, input_shape=[N_FEATURES]),\n",
    "        layers.Dropout(NN_DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(N_FEATURES//2, kernel_regularizer=regularizers.l1(0.001), activation=NN_ACTIVATION_2),\n",
    "        layers.Dropout(NN_DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(N_FEATURES//4, kernel_regularizer=regularizers.l1(0.001), activation=NN_ACTIVATION_2),\n",
    "        layers.Dropout(NN_DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(N_FEATURES//8, kernel_regularizer=regularizers.l1(0.001), activation=NN_ACTIVATION_2),\n",
    "        layers.Dropout(NN_DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(1)\n",
    "    ], name='deep'),\n",
    "]\n",
    "\n",
    "ensemble = train_ensemble(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned = ensemble.prune()\n",
    "top_3 = ensemble.prune(3)\n",
    "\n",
    "e_score = score_model(ensemble)\n",
    "p_score = score_model(pruned)\n",
    "t_score = score_model(top_3)\n",
    "b_score = score_model(ensemble.best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Ensemble Score:\\t{e_score}')\n",
    "# [m.model.name for m in ensemble.models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Pruned Score:\\t{p_score}')\n",
    "[m.model.name for m in pruned.models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Top 3 Score:\\t{t_score}')\n",
    "[m.model.name for m in top_3.models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best Model Score:\\t{b_score}')\n",
    "ensemble.best_model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception # stop for manual eval\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission compat check\n",
    "import optiver2023\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()\n",
    "\n",
    "for (test, revealed_targets, _) in iter_test:\n",
    "    X_test = preprocess(test)\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    submission = test[['row_id']].set_index('row_id') # needed to match rows\n",
    "    submission['target'] = y_pred\n",
    "    submission = submission.reset_index() # convert back for final CSV write\n",
    "    env.predict(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    res = pd.read_csv('/kaggle/working/submission.csv') # sanity check\n",
    "except FileNotFoundError:\n",
    "    res = pd.read_csv('./.data/submission.csv')\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
